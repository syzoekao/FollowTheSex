import numpy as np
import timeit
import netSTI.mydata as data
import netSTI.copula as copula

class MyError(Exception): 
	def __init__(self, arg): 
		self.arg = arg


def gen_adj_matrix_from_dd(ID, Npop, gen_dd, community = False, \
	ID_cluster = None, pCluster = 0.99):
	"""Generate adjacency matrix from an arbitrary degree sequence
	
	Arguments:
	ID (numpy array): an 1D numpy array with ID index from 0 to the population size. 
	Npop (integer): population size.  
	gen_dd (numpy array): this is a degree sequence stored in an 1D numpy array. 
	community (boolean): whether the graph is community structured or not. 
	ID_cluster (numpy array): if 'community = True', ID_cluster should be provided. ID_cluster is an
		1D numpy array indicating the cluster ID of individual. 
	pCluster (float): if 'community = True', pCluster should be provided. This is a probability of having 
		partners from the same community. 

	Returns: 
	tmpMatrix (numpy array): a symmetric adjacency matrix. 
	"""
	tmpMatrix = np.zeros((Npop, Npop))	

	if community == False:
		# counter is to keep track of the number of sex partners while generating sexual contact network
		counter = np.zeros(Npop)

		for i in ID: 
			n_samp = int(gen_dd[i] - counter[i])
			if n_samp > 0: 
				include_set = np.where(gen_dd - counter > 0)[0]		
				include_set = np.setdiff1d(include_set, i)
				has_rel_set = np.where(tmpMatrix[i] == 1)[0]
				include_set = np.setdiff1d(include_set, has_rel_set)
				sampID = np.array([])
				if (include_set.shape[0] > n_samp) & (n_samp > 0): 
					sampID = np.random.choice(include_set, size = n_samp, replace = False)
				if (include_set.shape[0] <= n_samp) & (n_samp > 0): 
					sampID = include_set
				if (n_samp <= 0) & (counter[i] > 0):
					sampID = np.random.choice(ID[ID != i], size = counter, replace = False)

				tmpMatrix[i, sampID] = 1
				tmpMatrix[sampID, i] = 1
				counter[i] += sampID.shape[0]
				counter[sampID] += 1
	else:
		if not isinstance(ID_cluster, np.ndarray): 
			raise TypeError('ID_cluster must be a numpy array')
		if not isinstance(pCluster, float): 
			raise TypeError('pCluster must be numeric (float)')
		# expected number of partners are outside of the community
		n_out_vec = np.random.binomial(gen_dd.astype(int), p = 1 - pCluster)
		n_in_vec = gen_dd - n_out_vec

		# use counter_out and counter_in to count partners
		counter_out = np.zeros(Npop)
		counter_in = np.zeros(Npop)

		for i in ID: 
			n_samp_out = int(n_out_vec[i] - counter_out[i])
			n_samp_in = int(n_in_vec[i] - counter_in[i])
			dum = (ID_cluster == ID_cluster[i])
			has_rel_set = np.where(tmpMatrix[i] == 1)[0]

			include_in_set = ID[dum]
			include_in_set = include_in_set[(n_in_vec[include_in_set] - counter_in[include_in_set]) > 0]
			include_in_set = np.setdiff1d(include_in_set, i)
			include_in_set = np.setdiff1d(include_in_set, has_rel_set)

			include_out_set = ID[~dum]
			include_out_set = include_out_set[(n_out_vec[include_out_set] - counter_out[include_out_set]) > 0]
			include_out_set = np.setdiff1d(include_out_set, has_rel_set)	

			sampID1 = np.array([]).astype(int)
			if n_samp_in > 0: 
				if include_in_set.shape[0] > n_samp_in:
					sampID1 = np.random.choice(include_in_set, size = n_samp_in, replace = False)
				else: 
					sampID1 = include_in_set

			sampID2 = np.array([]).astype(int)
			if n_samp_out > 0:
				if include_out_set.shape[0] > n_samp_out: 
					sampID2 = np.random.choice(include_out_set, size = n_samp_out, replace = False)
				else: 
					sampID2 = include_out_set

			sampID = np.concatenate((sampID1, sampID2))

			tmpMatrix[i, sampID] = 1
			tmpMatrix[sampID, i] = 1
			counter_in[i] += sampID1.shape[0]
			counter_in[sampID1] += 1	
			counter_out[i] += sampID2.shape[0]
			counter_out[sampID2] += 1

	return tmpMatrix


def period_Relation(agent_ID, part_ID, avg_dur, time_horizon): 
	''' Assign beginning and end times to each relationship
	
	Arguments: 
	agent_ID (numpy array): an 1D array of the agent ID. The length of the array should be the same
		as the part_ID
	part_ID (numpy array): an 1D array of the partner ID
	avg_dur (numpy array): an 1D array of the average relationship duration assigned to each individual 
		from CopulaDist class. 
	time_horizon (integer): number of cycles

	Returns: 
	rel_begin: a vector of beginning time of a relationship
	rel_end: a vector of end time of a relationship
	'''
	if agent_ID.shape[0] != part_ID.shape[0]: 
		MyError("The length of agent_ID and part_ID should be the same.")

	tmp_dur = np.round((avg_dur[agent_ID] + avg_dur[part_ID]) / 2)
	duration = np.round(np.random.exponential(tmp_dur)).astype(int)

	# the beginning cycle of the relationship could be negative 
	# the tmp vector is the minimum beginning time
	tmp_lb = 0 - duration
	vfunc = np.vectorize(np.random.uniform)
	rel_begin = np.ceil(vfunc(tmp_lb, (time_horizon - 1))).astype(int)
	rel_end = rel_begin + duration
	return rel_begin, rel_end


def generate_edge_list_array(tmpMatrix, avg_dur, time_horizon): 
	""" Creating the relationship between individuals using edge list format
	
	Arguments: 
	tmpMatrix (numpy array): an adjacency matrix
	avg_dur (numpy array): an 1D array of the duration assigned to each individual from CopulaDist

	Returns: 
	out_rel (numpy array): an edge list shaped as numpy array with 4 columns. Each row represents 
	a relationship. Column 0 is the ID of partner 1. Column 1 is the ID of partner 2. Column 2
	is the beginning cycle of the relationship. Column 3 is the end cycle of the relationship. 	
	"""
	agent_ID, part_ID = np.where(tmpMatrix == 1)
	dum = agent_ID < part_ID
	agent_ID = agent_ID[dum]
	part_ID = part_ID[dum]
	rel_beg, rel_end = period_Relation(agent_ID, part_ID, avg_dur, time_horizon = time_horizon)
	out_rel = np.vstack((agent_ID, part_ID, rel_beg, rel_end)).T

	'''
	if out_rel.shape[0] != np.sum(tmpMatrix) / 2: 
		MyError("row number of the edgelist is different than the sum of adjacency matrix divided by 2")
	'''
	return out_rel


def graph_generator(G, ID, Npop, Ndegree, time_horizon, years, \
	ID_cluster = None, pCluster = 0.99, independent = True): 
	''' Generating edge list array
	
	Arguments: 
	G (string): type of graphs. G can only be 'random', 'community', 'power_law', or 'empirical'
	ID (numpy array): an 1D array of individual ID ranging from 0 to (Npop - 1)
	Npop (integer): population size
	Ndegree (float or integer): average degree over the time_horizon
	time_horizon (integer): number of simulation cycles
	years (integer): number of simulation years
	ID_cluster (numpy array): cluster ID for each individual. This is only required when G == 'community'. 
	pCluster (float): probability that individuals form a relationship with individuals in the same community. 
		This is only used when G == 'community'. 
	independent (boolean): indicates whether or not the degree and duration of relationship should be correlated. 

	Return: 
	out_rel: an edge list shaped as numpy array with 4 columns. Each row represents 
	a relationship. Column 0 is the ID of partner 1. Column 1 is the ID of partner 2. Column 2
	is the beginning cycle of the relationship. Column 3 is the end cycle of the relationship. 	
	'''
	if G == "community": 
		if not isinstance(ID_cluster, np.ndarray): 
			raise TypeError('ID_cluster must be a numpy array')

	cop = copula.CopulaDist(Npop, graph = G, independent = independent)

	if G in ['random', 'community']: 
		gen_dd = cop.get_degree_poisson(Ndegree)
	if G == 'power_law': 
		gen_dd = cop.get_degree_power_law()
	if G == 'empirical': 
		gen_dd = cop.get_dd_empirical(years)

	gen_avg_dur = cop.get_avg_duration()

	if G != 'community': 
		tmpMatrix = gen_adj_matrix_from_dd(ID, Npop, gen_dd)
	else:
		tmpMatrix = gen_adj_matrix_from_dd(ID, Npop, gen_dd, community = True, \
			ID_cluster = ID_cluster, pCluster = pCluster)

	# generate edge list
	out_rel = generate_edge_list_array(tmpMatrix, avg_dur = gen_avg_dur, \
		time_horizon = time_horizon)
	return out_rel



class SumNet: 
	""" Summerize the networks and get network statistics.
	
	Arguments: 
	----------
	el (numpy array): edgelist with 4 columns
	Npop (integer): population size
	
	Notes: 
	------
	summarize_net_result generates 6 network statistics: 
	deg_all: degree across time horizon
	deg_a_window: degree in the evaluation window
	avg_deg_step: average degree per time step in the evaluation window
	iso_a_window: proportion of isolates in the evaluation window
	cor: correlation between deg_all and relationship duration
	avg_dur: average relationship duration
	"""

	def __init__(self, el, Npop): 
		self.el = el
		self.Npop = Npop

	def calc_avg_degree_per_step(self, time_horizon): 
		# Calculate average degree per time step
		mean_deg_per_step = np.zeros(time_horizon)
		for t in range(time_horizon): 
			tmp_el = self.el[np.where((self.el[:, 2] <= t) & (self.el[:, 3] >= t))]
			tmp_ix, tmp_n = np.unique(tmp_el[:, :2], return_counts = True)
			mean_deg_per_step[t] = np.sum(tmp_n) / self.Npop
		return mean_deg_per_step

	def sumarize_net_result(self, time_horizon, t_begin): 
		# calculate overall degree 
		tmp_ix, tmp_n = np.unique(self.el[:, :2], return_counts = True)
		tmp_degree = np.zeros(self.Npop)
		tmp_degree[tmp_ix] = tmp_n
		mean_deg_all = np.sum(tmp_degree) / self.Npop

		# calculate correlation between degree and duration
		tmpDur = np.zeros((self.Npop, self.Npop))
		tmpDur[:, :] = np.nan
		g_dur = self.el[:, 3] - self.el[:, 2]
		for i in range(self.el.shape[0]): 
			x = self.el[i, 0]
			y = self.el[i, 1]
			tmpDur[x, y] = g_dur[i]
			tmpDur[y, x] = g_dur[i]
		tmp_dur = np.nanmean(tmpDur, axis = 1)
		tmp_ix = np.isnan(tmp_dur)
		cor = np.round(np.corrcoef(tmp_degree[~tmp_ix], tmp_dur[~tmp_ix])[0, 1], 5)
		mean_dur = np.nansum(tmpDur) / np.sum(tmp_degree)

		# calculate degree over the analysis window
		tmp_ix, tmp_n = np.unique(self.el[np.where(self.el[:, 3] > t_begin), :2], return_counts = True)
		tmp_degree = np.zeros(self.Npop)
		tmp_degree[tmp_ix] = tmp_n
		mean_deg_a_window = np.sum(tmp_degree) / self.Npop

		# calculate the proportion of isolates in the analysis window
		iso_a_window = np.sum(tmp_degree == 0) / self.Npop

		# Calculate average degree per time step
		mean_deg_per_step = self.calc_avg_degree_per_step(time_horizon)
		mean_deg_per_step = np.mean(mean_deg_per_step[t_begin:])

		return {'deg_all': mean_deg_all, 'deg_a_window': mean_deg_a_window, \
		'avg_deg_step': mean_deg_per_step, 'iso_a_window': iso_a_window, 'cor': cor, \
		'avg_dur': mean_dur}

