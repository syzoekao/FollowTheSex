import numpy as np
import networkx as nx 
import pandas as pd 
import copy
import timeit
import operator
import scipy.stats as stats
import netSTI.mydata as data
import netSTI.copula as copula

class MyError(Exception): 
	def __init__(self, arg): 
		self.arg = arg

###################################################################
# common functions

def get_params(unit = 26): 
	return data.Params(unit).init_prev, \
	data.Params(unit).pInf, \
	data.Params(unit).pCondom, \
	data.Params(unit).redCondom, \
	data.Params(unit).pRec, \
	data.Params(unit).pScr, \
	data.Params(unit).pContact_PN, \
	data.Params(unit).pContact_ept, \
	data.Params(unit).pContact_tr, \
	data.Params(unit).p_treat_PN, \
	data.Params(unit).p_treat_ept, \
	data.Params(unit).p_treat_tr, \
	data.Params(unit).max_contact, \
	data.Params(unit).max_ept, \
	data.Params(unit).alpha, \
	data.Params(unit).cMedicine, \
	data.Params(unit).cInvestigate, \
	data.Params(unit).cTest, \
	data.Params(unit).n_cluster, \
	data.Params(unit).q, \
	data.Params(unit).discount_rate 


def gen_adj_matrix_from_dd(ID, Npop, gen_dd, d_distribution = "random", \
	ID_cluster = None, pCluster = 0.99):

	# keep track of the sexual partnership using adjacency matrix
	tmpMatrix = np.zeros((Npop, Npop))	

	if d_distribution != 'community':
		# counter is to keep track of the number of sex partners while generating sexual contact network
		counter = np.zeros(Npop)

		for i in ID: 
			n_samp = int(gen_dd[i] - counter[i])
			if n_samp > 0: 
				include_set = np.where(gen_dd - counter > 0)[0]		
				include_set = np.setdiff1d(include_set, i)
				has_rel_set = np.where(tmpMatrix[i] == 1)[0]
				include_set = np.setdiff1d(include_set, has_rel_set)
				
				if d_distribution == "random":
					if include_set.shape[0] > n_samp: 
						sampID = np.random.choice(include_set, size = n_samp, replace = False)
					else: 
						sampID = include_set	
				else: # d_distribution == "power_law":
					tmp_p = gen_dd[include_set] / np.sum(gen_dd[include_set])
					if include_set.shape[0] > n_samp: 
						sampID = np.random.choice(include_set, p = tmp_p, size = n_samp, replace = False)
					else: 
						sampID = include_set			

				tmpMatrix[i, sampID] = 1
				tmpMatrix[sampID, i] = 1
				counter[i] += sampID.shape[0]
				counter[sampID] += 1
	else:
		# expected number of partners are outside of the community
		n_out_vec = np.random.binomial(gen_dd.astype(int), p = 1 - pCluster)
		n_in_vec = gen_dd - n_out_vec

		# use counter_out and counter_in to count partners
		counter_out = np.zeros(Npop)
		counter_in = np.zeros(Npop)

		for i in ID: 
			n_samp_out = int(n_out_vec[i] - counter_out[i])
			n_samp_in = int(n_in_vec[i] - counter_in[i])
			dum = (ID_cluster == ID_cluster[i])
			has_rel_set = np.where(tmpMatrix[i] == 1)[0]

			include_in_set = ID[dum]
			include_in_set = include_in_set[(n_in_vec[include_in_set] - counter_in[include_in_set]) > 0]
			include_in_set = np.setdiff1d(include_in_set, i)
			include_in_set = np.setdiff1d(include_in_set, has_rel_set)

			include_out_set = ID[~dum]
			include_out_set = include_out_set[(n_out_vec[include_out_set] - counter_out[include_out_set]) > 0]
			include_out_set = np.setdiff1d(include_out_set, has_rel_set)	

			sampID1 = np.array([]).astype(int)
			if n_samp_in > 0: 
				if include_in_set.shape[0] > n_samp_in:
					sampID1 = np.random.choice(include_in_set, size = n_samp_in, replace = False)
				else: 
					sampID1 = include_in_set

			sampID2 = np.array([]).astype(int)
			if n_samp_out > 0:
				if include_out_set.shape[0] > n_samp_out: 
					sampID2 = np.random.choice(include_out_set, size = n_samp_out, replace = False)
				else: 
					sampID2 = include_out_set

			sampID = np.concatenate((sampID1, sampID2))

			tmpMatrix[i, sampID] = 1
			tmpMatrix[sampID, i] = 1
			counter_in[i] += sampID1.shape[0]
			counter_in[sampID1] += 1	
			counter_out[i] += sampID2.shape[0]
			counter_out[sampID2] += 1	
	return tmpMatrix


def period_Relation(agent_ID, part_ID, avg_dur, time_horizon): 
	''' Assign beginning and end times to each relationship
	
	Arguments: 
	n_rel (integer): # of relaltionships
	dur (numpy vector): a vector of mean duration 
	dur_dist (numpy vector): a vector of distribution of duration. This is a proportion
	time_horizon (integer): number of cycles

	Returns: 
	rel_begin: a vector of beginning time of a relationship
	rel_end: a vector of end time of a relationship
	'''
	tmp_dur = (avg_dur[agent_ID] + avg_dur[part_ID]) / 2

	rel_begin = np.random.choice(list(range(0, time_horizon)), part_ID.shape[0])
	duration = np.round(np.random.exponential(tmp_dur)).astype(int)
	rel_end = rel_begin + duration
	return rel_begin, rel_end


def generate_edge_list_array(sampMatrix, Npop, avg_dur, time_horizon): 
	""" Creating the relationship between individuals using edge list format
	
	Arguments: 
	sampMatrix (numpy array): an array of probability of tie formation in each cell. 
	Npop (integer): Population size. 

	Returns: 
	out_rel (numpy array): an edge list shaped as numpy array with 4 columns. Each row represents 
	a relationship. Column 0 is the ID of partner 1. Column 1 is the ID of partner 2. Column 2
	is the beginning cycle of the relationship. Column 3 is the end cycle of the relationship. 	
	"""
	out_rel = [None] * Npop

	for i in range(sampMatrix.shape[0]): 
		part_ID = np.where((sampMatrix[i] == 1))[0]
		part_ID = part_ID[part_ID > i]
		agent_ID = np.repeat(i, part_ID.shape[0])
		rel_beg, rel_end = period_Relation(agent_ID, part_ID, avg_dur, time_horizon = time_horizon)
		out_rel[i] = np.vstack((agent_ID, part_ID, rel_beg, rel_end)).T

	out_rel = np.vstack(out_rel)
	if out_rel.shape[0] != np.sum(sampMatrix) / 2: 
		MyError("row number of the edgelist is different than the sum of adjacency matrix divided by 2")
	return out_rel


def random_graph_generator(ID, Npop, Ndegree, time_horizon, independent = True): 
	"""Generate cumulative random networks
	
	Arguments: 
	ID: a numpy vector of individual IDs.
	Npop (integer): population size 
	Ndegree: an integer indicates the average number of cumulative sex partners that an individual has
	within the time_horizon.
	dur (numpy vector): a vector of mean duration 
	dur_dist (numpy vector): a vector of distribution of duration. This is a proportion
	time_horizon (integer): number of cycles

	Returns: 
	out_rel (numpy array): an edge list shaped as numpy array with 4 columns. Each row represents 
	a relationship. Column 0 is the ID of partner 1. Column 1 is the ID of partner 2. Column 2
	is the beginning cycle of the relationship. Column 3 is the end cycle of the relationship. 

	====
	These are the original code... 
	p_tie = ((Ndegree * Ndegree)/(Ndegree * (Npop - 1))) / 2
	tmpMatrix = np.random.binomial(1, size = (Npop, Npop), p = p_tie)
	tmpMatrix = tmpMatrix + tmpMatrix.T
	tmpMatrix[tmpMatrix > 1] = 1
	np.fill_diagonal(tmpMatrix, 0)

	gen_dd = np.sum(tmpMatrix, 1)
	====
	"""

	cop = copula.CopulaDist(Npop, independent = independent)
	gen_dd = cop.get_degree_poisson(Ndegree)
	gen_avg_dur = cop.get_avg_duration()

	# Get the adjacency matrix
	tmpMatrix = gen_adj_matrix_from_dd(ID, Npop, gen_dd, d_distribution = "random")

	# generate edge list
	out_rel = generate_edge_list_array(tmpMatrix, Npop = Npop, avg_dur = gen_avg_dur, \
		time_horizon = time_horizon)
	return out_rel


def community_graph_generator(ID, Npop, Ndegree, ID_cluster, time_horizon, pCluster = 0.99, independent = True): 
	"""Generate cumulative community structured networks
	
	Arguments: 
	ID: a numpy vector of individual IDs.
	Npop (integer): population size
	Ndegree: an integer indicates the average number of cumulative sex partners that an individual has
	within the time_horizon.
	ID_cluster (numpy array): a vector of cluster ID for each ID. 
	dur (numpy vector): a vector of mean duration 
	dur_dist (numpy vector): a vector of distribution of duration. This is a proportion
	time_horizon (integer): number of cycles
	pCluster (float): the probabilty of assortative matching within the same community 

	Returns: 
	out_rel (numpy array): an edge list shaped as numpy array with 4 columns. Each row represents 
	a relationship. Column 0 is the ID of partner 1. Column 1 is the ID of partner 2. Column 2
	is the beginning cycle of the relationship. Column 3 is the end cycle of the relationship. 

	====
	This are the original code: 
	# calculate the probability of tie formation with individuals in and outside of the community
	p_in_cl = ((Ndegree * pCluster) / (Npop / np.unique(ID_cluster).shape[0] - 1)) / 2
	p_out_cl = ((Ndegree * (1 - pCluster)) / (Npop - (Npop / np.unique(ID_cluster).shape[0]))) / 2

	# making a probability matrix 
	tmpMatrix = np.tile(ID_cluster[:, None], Npop)
	tmpMatrix = (tmpMatrix == tmpMatrix.T)
	tmpMatrix = tmpMatrix * p_in_cl + (1 - tmpMatrix) * p_out_cl
	np.fill_diagonal(tmpMatrix, 0)

	# sample the whether two individuals are sex partners or not
	tmpMatrix = np.random.binomial(1, p = tmpMatrix)
	tmpMatrix = tmpMatrix + tmpMatrix.T
	tmpMatrix[tmpMatrix > 1] = 1
	np.fill_diagonal(tmpMatrix, 0)
	====
	"""
	cop = copula.CopulaDist(Npop, independent = independent)
	gen_dd = cop.get_degree_poisson(Ndegree)
	gen_avg_dur = cop.get_avg_duration()

	# Get the adjacency matrix
	tmpMatrix = gen_adj_matrix_from_dd(ID, Npop, gen_dd, d_distribution = "community", \
		ID_cluster = ID_cluster, pCluster = 0.99)

	# generate edge list
	out_rel = generate_edge_list_array(tmpMatrix, Npop = Npop, avg_dur = gen_avg_dur, \
		time_horizon = time_horizon)
	return out_rel


def power_law_graph_generator(ID, Npop, time_horizon, n_yrs = 10, independent = True): 
	"""Generate cumulative power law networks
	
	Arguments: 
	ID: a numpy vector of individual IDs.
	Npop (integer): population size
	Ndegree: an integer indicates the average number of cumulative sex partners that an individual has
	within the time_horizon.
	dur (numpy vector): a vector of mean duration 
	dur_dist (numpy vector): a vector of distribution of duration. This is a proportion
	time_horizon (integer): number of cycles

	Returns: 
	out_rel (numpy array): an edge list shaped as numpy array with 4 columns. Each row represents 
	a relationship. Column 0 is the ID of partner 1. Column 1 is the ID of partner 2. Column 2
	is the beginning cycle of the relationship. Column 3 is the end cycle of the relationship. 
	"""
	cop = copula.CopulaDist(Npop, n_yrs, power_law = True, independent = independent)
	gen_dd = cop.get_degree_power_law(n_yrs)
	gen_avg_dur = cop.get_avg_duration()

	# generate degree sequence for everyone in the population
	ix_sort = np.argsort(-gen_dd)
	gen_dd = gen_dd[ix_sort]
	gen_avg_dur = gen_avg_dur[ix_sort]
	
	tmpMatrix = gen_adj_matrix_from_dd(ID, Npop, gen_dd, d_distribution = "power_law")

	# generate edge list
	out_rel = generate_edge_list_array(tmpMatrix, Npop = Npop, avg_dur = gen_avg_dur, \
		time_horizon = time_horizon)
	return out_rel


# graph summary
def annual_G_summary(annual_rel_dict, g): 
	# the input has to be networkx object
	G = nx.Graph(annual_rel_dict[g])
	Npop = len(G.node)
	node_degree = dict(G.degree())
	degrees = [val for key, val in node_degree.items()]
	avg_degree = np.mean(degrees)
	var_degree = np.var(degrees)
	degree_dist = {i: degrees.count(i)/Npop for i in set(degrees)}
	prop_isolates = len([x for x in degrees if x == 0])/Npop
	Gc = max(nx.connected_component_subgraphs(G), key=len)
	prop_in_Gc = len(Gc.node())/Npop
	avg_path = nx.average_shortest_path_length(G)

	return {"prop_isolates": prop_isolates, "avg_degree": avg_degree, "var_degree": var_degree, 
		"prop_in_Gc":prop_in_Gc, "avg_path":avg_path, "degree_dist": degree_dist}


def pert(n, x_min, x_max, x_mode, lam = 4): 
	x_range = x_max-x_min
	if x_range == 0: 
		np.repeat(x_min, n)
	mu = ( x_min + x_max + lam * x_mode ) / ( lam + 2 )
	if mu == x_mode: 
		v = (lam/2) + 1
	else: 
		v = ((mu-x_min)*(2*x_mode-x_min-x_max))/(( x_mode - mu ) * ( x_max - x_min ))
	w = (v*(x_max - mu))/(mu-x_min)
	return stats.beta.rvs(v, w, size = n)*x_range + x_min


def get_instantaneous_sex_net(rel_hist, I, T, n_partners, Npop, t): 
	""" Extract information of the instantaneous sexual network

	Argument:
	rel_hist (numpy array): relationship history
	I (numpy array): a vector of infected status
	T (numpy array): a vector of treated status
	n_partners (numpy array): a vector of number of sex partners
	t (integer): time step

	Return: 
	tmp_rel (numpy array): temporary sex relationship at time t
	n_partners (numpy array): modified n_partners, which calculate the current number
	of sex partners at time t
	"""
	# 1. get current relationships at time t
	tmp_rel = rel_hist[(rel_hist[:, 2] <= t) & (rel_hist[:, 3] >= t)]
	# 1.1 get # of relationships of the infected
	activeID, tmp_n = np.unique(tmp_rel[:, :2], return_counts = True)
	n_partners[activeID] = tmp_n
	mean_partners = np.sum(tmp_n) / Npop
	# 2. keep relationships that only have one infected ID
	dum = (I[tmp_rel[:, 0]] + I[tmp_rel[:, 1]]) == 1
	tmp_rel = tmp_rel[dum]
	# 3. keep relationships that no one is on treatment
	dum = (T[tmp_rel[:, 0]] + T[tmp_rel[:, 1]]) == 0
	tmp_rel = tmp_rel[dum]
	return tmp_rel, n_partners, mean_partners

def trans_dynamics(I, tmp_rel, n_acts, pInf, pCondom, redCondom, n_partners): 
	infID = np.where(I == 1)[0]
	avg_acts = (n_acts[tmp_rel[:, 0]] + n_acts[tmp_rel[:, 1]]) / 2
	dum = np.random.binomial(1, \
		p = (1 - (1 - pInf * (pCondom * (1 - redCondom) + (1 - pCondom))) ** avg_acts))
	new_infID = np.unique(tmp_rel[dum == 1, :2])
	new_infID = np.setdiff1d(new_infID, infID)
	return infID, new_infID


def notify_contact_deliver_sex_part(tmp_screen_I, rel_hist, unit_per_year, pContact, alpha, t): 
	dum1 = 1 * np.in1d(rel_hist[:, 0], tmp_screen_I)
	dum2 = 1 * np.in1d(rel_hist[:, 1], tmp_screen_I)
	dum = ((dum1 + dum2) == 1)
	screen_rel = rel_hist[dum]
	# get right time period for testing 
	dum = (screen_rel[:, 2] <= t) & ((t - screen_rel[:, 3]) <= (unit_per_year / 2))
	screen_rel = screen_rel[dum]
	tmp = np.round((t - screen_rel[:, 3]) * ((t - screen_rel[:, 3]) >= 0) / 2)
	dum = np.random.binomial(1, p = pContact * (np.exp(-alpha * tmp)), size = screen_rel.shape[0])
	tmp_name, tmp_count = np.unique(screen_rel[dum == 1, :2], return_counts = True)
	dum = ~np.in1d(tmp_name, tmp_screen_I)
	tmp_name = tmp_name[dum]
	tmp_count = tmp_count[dum]
	return tmp_name, tmp_count


def contact_trace_name(n_name_trace, max_contact, tmp_screen_I, infID): 
	tmp_name = np.where(n_name_trace > 0)[0]
	if tmp_name.shape[0] > max_contact: 
		tmp_count = n_name_trace[tmp_name]
		tmp_sort = np.argsort(-tmp_count)
		tmp_name = tmp_name[tmp_sort]
		tmp_name = tmp_name[:(max_contact + 1)]
	num_contact = tmp_name.shape[0]
	dum = (np.random.binomial(1, p = p_treat_tr, size = num_contact) == 1)
	trace_test_name = tmp_name[dum]
	# if a partner get tested due to contact tracing, replace the n_name_trace with 0
	n_name_trace[trace_test_name] = 0 
	num_test = trace_test_name.shape[0]
	treat_name = trace_test_name[np.in1d(trace_test_name, infID)]
	tmp_screen_I = np.concatenate((tmp_screen_I, treat_name))
	return tmp_screen_I, tmp_name, n_name_trace, num_contact, num_test, treat_name


def SIR_net_generator(meanActs, run, Npop, years = 20, days = 14, 
	strategy = "null", graph = "random", independent = True, calibration = False): 
	'''
	Npop = 5000
	years = 20
	days = 14 # 14 days; bi-weekly time step
	run = np.random.choice(list(range(1, 1001)), 1)
	graph = "power_law"
	strategy = "PN" 
	independent = True
	calibration = False
	meanActs = 40
	# 4 strategies: do nothing, EPT, contact tracing_degree (contact high degree nodes first), contact tracing_chronology (first come, first serve.)
	'''

	Ndegree = 4 * years
	unit_per_year = int(365 / days)
	time_horizon = unit_per_year * years
	acts = meanActs / unit_per_year

	init_prev, pInf, pCondom, redCondom, pRec, pScr, \
	pContact_PN, pContact_ept, pContact_tr, p_treat_PN, p_treat_ept, p_treat_tr, \
	max_contact, max_ept, alpha, cMedicine, cInvestigate, cTest, \
	n_cluster, q, discount_rate = get_params(unit_per_year)

	init_inf = int(Npop * init_prev)
	if calibration == False: 
		np.random.seed(run)

	ID = np.arange(Npop)
	ID_cluster = (np.floor(ID / (Npop/n_cluster)) + 1).astype(int)
	S = np.ones(Npop)
	I = np.zeros(Npop)
	T = np.zeros(Npop) # this state is only for recording time of treatment
	cum_dx = np.zeros(Npop)

	# set up output vectors
	out_S = np.zeros(time_horizon) # prevalence of S
	out_I = np.zeros(time_horizon) # prevalence of I
	out_newI = np.zeros(time_horizon)
	out_newRec = np.zeros(time_horizon)
	out_nDeliver = np.zeros(time_horizon)
	out_nContactTrace = np.zeros(time_horizon)
	out_nNotified = np.zeros(time_horizon)
	out_nTrueTreat = np.zeros(time_horizon)
	out_nOvertreat = np.zeros(time_horizon)
	out_nTest = np.zeros(time_horizon)
	out_nScreen = np.zeros(time_horizon)
	out_nTrueTreatIntervention = np.zeros(time_horizon)
	out_pEfficient = np.zeros(time_horizon)
	out_avg_degree = np.zeros(time_horizon)
	out_CostMedicine = np.zeros(time_horizon)
	out_CostTracing = np.zeros(time_horizon)
	out_CostTest = np.zeros(time_horizon)
	out_Util = np.zeros(time_horizon)
	out_p_cum_dx = np.zeros(years) # simulation outcome for calibration

	if graph == "random": 
		rel_hist = random_graph_generator(ID, Npop, Ndegree, time_horizon, independent = independent)
	elif graph == "community": 
		rel_hist = community_graph_generator(ID, Npop, Ndegree, ID_cluster, time_horizon, \
			pCluster = 0.99, independent = independent)
	else: # graph == "power_law": 
		rel_hist = power_law_graph_generator(ID, Npop, time_horizon, \
			n_yrs = n_yrs, independent = independent)

	tmp_name, tmp_count = np.unique(rel_hist[:, :2], return_counts = True) 
	count_all = np.zeros(Npop)
	count_all[tmp_name] = tmp_count
	if graph in ["power_law" , "random"]: 
		infID = np.random.choice(ID, init_inf, \
			p = count_all/np.sum(count_all), replace = False)
	else: 
		init_select = np.where(ID_cluster == 1)[0]
		infID = np.sort(np.random.choice(init_select, init_inf, \
			p = count_all[init_select] / np.sum(count_all[init_select]), replace = False))

	I[infID] = 1
	S[infID] = 0

	n_partners = np.zeros(Npop) 
	n_acts = np.repeat(meanActs / unit_per_year, Npop)

	n_notification = np.zeros(Npop)
	n_name_trace = np.zeros(Npop)
	n_infection = np.zeros(Npop) # only count new infection in the analysis time (last 10 years)
	n_intervention = np.zeros(Npop) # only count new infection in the analysis time (last 10 years)

	for t in range(0, time_horizon): 
	# for t in range(0, 52):

		## transmission dynamics
		tmp_rel, n_partners, mean_partners = get_instantaneous_sex_net(rel_hist, I, T, \
			n_partners, Npop, t)
		infID, new_infID = trans_dynamics(I, tmp_rel, n_acts, pInf, pCondom, redCondom, n_partners)

		## Recovered from treated
		treatID = np.where(T == 1)[0]
		T[treatID] = 0
		S[treatID] = 1

		## screening and testing
		tmp_screen_I = infID[np.random.binomial(1, p = pScr, size = infID.shape[0]) == 1]
		I[tmp_screen_I] = 0
		T[tmp_screen_I] = 1
		cum_dx[tmp_screen_I] += 1
		S_ID = np.where(S == 1)[0]
		tmp_screen_S = S_ID[np.random.binomial(1, p = pScr, size = S_ID.shape[0]) == 1]
		out_nScreen[t] = tmp_screen_I.shape[0] + tmp_screen_S.shape[0]	
		out_nTest[t] = tmp_screen_I.shape[0] + tmp_screen_S.shape[0]
		out_nTrueTreat[t] = tmp_screen_I.shape[0]

		if t >= ((time_horizon - unit_per_year * 10) - 1):  
			# infected ID who get treated
			if strategy == "tracing": 
				tmp_screen_I, contact_name, n_name_trace, num_contact, num_test, treat_name = \
					contact_trace_name(n_name_trace, max_contact, tmp_screen_I, infID)
				out_nTrueTreatIntervention[t] = treat_name.shape[0]
				dum_dx[treat_name] += 1
				out_nTest[t] += num_test
				n_infection[new_infID] += 1
				n_intervention[contact_name] += 1
				tmp_name, tmp_count = notify_contact_deliver_sex_part(tmp_screen_I, \
					rel_hist, unit_per_year, pContact_tr, alpha, t)
				n_name_trace[tmp_name] += tmp_count
				out_nContactTrace[t] = num_contact
				out_nTrueTreat[t] = tmp_screen_I.shape[0]
				out_pEfficient[t] = out_nTrueTreatIntervention[t] / out_nContactTrace[t - 1]
				I[tmp_screen_I] = 0
				T[tmp_screen_I] = 1

			if strategy == "EPT": 			
				tmp_name, tmp_count = notify_contact_deliver_sex_part(tmp_screen_I, rel_hist, \
					unit_per_year, pContact_ept, alpha, t)
				out_nDeliver[t] = np.sum(tmp_count)
				n_infection[new_infID] += 1
				n_intervention[tmp_name] += 1
				dum = (np.random.binomial(1, p = 1 - (1 - p_treat_ept) ** tmp_count) == 1)
				tmp_name = tmp_name[dum]
				tmp_ept_treat = tmp_name[np.in1d(tmp_name, infID)]
				out_nTrueTreat[t] = tmp_screen_I.shape[0] + tmp_ept_treat.shape[0]
				out_nOvertreat[t] = tmp_name.shape[0] - tmp_ept_treat.shape[0]
				out_nTrueTreatIntervention[t] = tmp_ept_treat.shape[0]
				out_pEfficient[t] = out_nTrueTreatIntervention[t] / out_nDeliver[t]
				tmp_screen_I = np.concatenate((tmp_screen_I, tmp_ept_treat))
				I[tmp_screen_I] = 0
				T[tmp_screen_I] = 1

			if strategy == "PN": 
				if t >= (time_horizon - unit_per_year * 10): 
					dum = (np.random.binomial(1, \
						p = 1 - (1 - p_treat_PN) ** (n_notification[notify_name])) == 1)
					notify_test_name = notify_name[dum]
					out_nTest[t] += notify_test_name.shape[0]
					notify_true_treat_name = notify_test_name[np.in1d(notify_test_name, infID)]
					cum_dx[notify_true_treat_name] += 1
					out_nTrueTreatIntervention[t] = notify_true_treat_name.shape[0]
					out_pEfficient[t] = out_nTrueTreatIntervention[t] / out_nNotified[t - 1]
					tmp_screen_I = np.concatenate((tmp_screen_I, notify_true_treat_name))
					n_notification[n_notification > 0] = 0

				notify_name, tmp_count = notify_contact_deliver_sex_part(tmp_screen_I, rel_hist, \
					unit_per_year, pContact_PN, alpha, t)
				n_notification[notify_name] += tmp_count
				n_infection[new_infID] += 1
				n_intervention[notify_name] += 1

				out_nNotified[t] = notify_name.shape[0]
				out_nTrueTreat[t] = tmp_screen_I.shape[0]

				I[tmp_screen_I] = 0
				T[tmp_screen_I] = 1

		## spontaneous recovered ID
		dum = np.random.binomial(1, p = pRec, size = infID.shape[0]) == 1
		new_recID = infID[dum]
		S[new_recID] = 1
		I[new_recID] = 0
		out_newRec[t] = new_recID.shape[0]

		## updated the health state of the newly infected ID
		S[new_infID] = 0
		I[new_infID] = 1

		out_S[t] = np.mean(S)
		out_I[t] = np.mean(I)
		out_newI[t] = new_infID.shape[0]

		d_factor = (1 / (1 + discount_rate)) ** (t + 1)
		out_CostMedicine[t] = (out_nTrueTreat[t] + out_nOvertreat[t]) * (cMedicine * d_factor)
		out_CostTracing[t] = out_nContactTrace[t] * (cInvestigate * d_factor)
		out_CostTest[t] = out_nTest[t] * (cTest * d_factor)
		out_Util[t] = np.sum((1 * (1 - I) + q * I)) * d_factor

		out_avg_degree[t] = mean_partners

		if ((t + 1) % unit_per_year) == 0: 
			yr_t = int((t + 1) / unit_per_year) - 1
			out_p_cum_dx[yr_t] = np.sum(cum_dx > 0) / Npop
			cum_dx[cum_dx > 0] = 0

	if calibration == True: 
		return out_I[-260:]
	else: 
		filt_time = range((time_horizon - 26 * 10), time_horizon)
		sum_all = {}
		sum_all["S"] = np.nanmean(out_S[filt_time])
		sum_all["I"] = np.nanmean(out_I[filt_time])
		sum_all["newI"] = np.nansum(out_newI[filt_time])
		sum_all["nDeliver"] = np.nansum(out_nDeliver[filt_time])
		sum_all["nContactTrace"] = np.nansum(out_nContactTrace[filt_time])
		sum_all["nNotified"] = np.nansum(out_nNotified[filt_time])
		sum_all["nTrueTreat"] = np.nansum(out_nTrueTreat[filt_time])
		sum_all["nOvertreat"] = np.nansum(out_nOvertreat[filt_time])
		sum_all["nTest"] = np.nansum(out_nTest[filt_time])
		sum_all["nScreen"] = np.nansum(out_nScreen[filt_time])
		sum_all["nTrueTreatIntervention"] = np.nansum(out_nTrueTreatIntervention[filt_time])
		sum_all["pEfficient"] = np.nanmean(out_pEfficient[filt_time])
		sum_all["pEverInfected"] = np.sum(n_infection > 0) / Npop
		sum_all["averageTimesInfected"] = np.mean(n_infection[n_infection > 0] / 10)
		sum_all["nIntervention"] = np.nansum(n_intervention)
		sum_all["pEverBeenIntervention"] = np.sum(n_intervention > 0) / Npop
		sum_all["avgTimesBeenIntervene"] = np.mean(n_intervention[n_intervention > 0] / 10)
		sum_all["CostMedicine"] = np.nansum(out_CostMedicine[filt_time])
		sum_all["CostTracing"] = np.nansum(out_CostTracing[filt_time])
		sum_all["CostTest"] = np.nansum(out_CostTest[filt_time])
		sum_all["TotalCost"] = sum_all["CostMedicine"] + sum_all["CostTracing"] + sum_all["CostTest"]
		sum_all["Util"] = np.nansum(out_Util[filt_time])
		sum_all["n_cluster"] = np.unique(ID_cluster[I == 1]).shape[0]

		return {"run": run, "summary": sum_all, "avg_degree": out_avg_degree.tolist(), \
		"p_cumulative_dx": out_p_cum_dx[-10:].tolist(), "I": out_I.tolist()}




