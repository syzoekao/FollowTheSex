import numpy as np
import networkx as nx 
import pandas as pd 
import copy
import timeit
import operator
import scipy.stats as stats
# import igraph as ig
# from plDist import plDistMap
import netSTI.mydata as data

# plDistMap = dict(zip(list(range(1, 251)), plDistMap))

'''
# power law distribution 
f = open('PowerLawDist.txt', 'r')
for line in f: 
    temp = line.split(',')
plDist = [float(e.strip()) for e in temp]
f.close()
degree_seq = list(range(1, 251))
plDist = dict(zip(degree_seq, plDist))
'''

###################################################################
# common functions

def period_Relation(N, t, time_horizon): 
	'''
	average frequency per partner per year: 
	k = np.array([0.034, 0.122, 0.073, 0.063, 0.453, 0.185, 0.02])
	mean_freq_per_partner_per_year = np.sum(np.array([1, (2+5)/2, (6+11)/2, (12+23)/2, (24+35)/2, (36+51)/2, (52+155)/2])*k/(np.sum(k)))
	the mean frequency of sex per partner per year is 27 times. 
	'''
	# real_time = (t-1)*12
	real_time = 0
	rel_begin = np.random.choice(list(range(0, time_horizon)), N) + real_time
	dur = np.array(list(range(0, 37, 1))) # duration of (casual) relationship (months): 0 means that the relationship lasts less than a month. 
	dur_dist = np.array([0.558] + [0.216/6]*6 + [0.073/6]*6 + [0.074/12]*12 + [0.023/12]*12)
	dur_dist = dur_dist/np.sum(dur_dist)
	duration = np.random.choice(dur, N, p = dur_dist) 
	rel_end = duration + rel_begin
	rel_begin[rel_begin >= time_horizon] = time_horizon
	rel_end[rel_end >= time_horizon] = time_horizon
	rel_begin = rel_begin.tolist()
	rel_end = rel_end.tolist()
	out = [{"begin": rel_begin[x], "end": rel_end[x]} for x in range(len(rel_begin))]
	return out


def inf_sample(key, inf_contact, pInf): 
	temp = inf_contact[key]
	temp2 = np.random.binomial(1, pInf, len(inf_contact[key])).tolist()
	out = {key: [temp[x] for x in range(len(temp)) if temp2[x] == 1]}
	return out


def k_regular_graph_generator(node, Ndegree, plDistMap, time_horizon, t_end = 1): 
	# creating 5 years of annual networkss
	out_rel_dict = dict([(key, {}) for key in range(1, t_end + 1)])
	sum_exist = []
	for t in range(1, t_end + 1): 
		temp_rel_dict = dict([(key, {}) for key in node])
		existing_links = 0

		# find the relationships that overlap between year t-1 and year t
		if t > 1: 
			temp_for_existing = copy.deepcopy(out_rel_dict[t-1])	
			for i, v in temp_for_existing.items(): 
				for i2, v2 in v.items(): 
					temp_for_existing[i][i2]["existing"] = 1
			for i, v in temp_for_existing.items(): 
				temp_rel_dict[i].update({key: val for key, val in v.items() if val["end"] >= t*12}) 
			existing_links = sum([len(val) for key, val in temp_rel_dict.items()])
				
		for i in range(len(node)): 
			focalID = node[i]
			N_add = Ndegree - len(temp_rel_dict[focalID])
			if N_add > 0: 
				in_market = [key for key, val in temp_rel_dict.items() if (len(val) < Ndegree) and (key != focalID)]
				in_market = list(set(in_market) - set([key for key, val in temp_rel_dict[focalID].items()]))
				if N_add >= len(in_market): 
					contact = in_market
				else: 
					contact = np.random.choice(in_market, N_add, replace = False).tolist()
				temp = period_Relation(len(contact), t, time_horizon)
				for y in range(len(temp)): 
					temp[y]['existing'] = 0
				temp_rel_dict[focalID].update({contact[x]: temp[x] for x in range(len(temp))})
				for x in range(len(contact)):	
					temp_rel_dict[contact[x]].update(copy.deepcopy({focalID: temp[x]}))
		out_rel_dict[t] = temp_rel_dict
		total_links = sum([len(val) for key, val in temp_rel_dict.items()])
		# print(existing_links)
		sum_exist.append(existing_links/total_links)
	return out_rel_dict


def k_ring_generator(node, Ndegree, plDistMap, time_horizon, t_end = 1): 
	# creating 5 years of annual networkss
	out_rel_dict = dict([(key, {}) for key in range(1, t_end + 1)])
	sum_exist = []
	Npop = len(node)

	for t in range(1, t_end + 1): 
		temp_rel_dict = dict([(key, {}) for key in node])
		existing_links = 0

		# find the relationships that overlap between year t-1 and year t
		if t > 1: 
			temp_for_existing = copy.deepcopy(out_rel_dict[t-1])	
			for i, v in temp_for_existing.items(): 
				for i2, v2 in v.items(): 
					temp_for_existing[i][i2]["existing"] = 1
			for i, v in temp_for_existing.items(): 
				temp_rel_dict[i].update({key: val for key, val in v.items() if val["end"] >= t*12}) 
			existing_links = sum([len(val) for key, val in temp_rel_dict.items()])

		position = np.random.permutation(node).tolist()
		# position = node
		m = int(Ndegree/2) # m neighbors
		for i in range(len(position)): 
			focalID = position[i]
			if Ndegree % 2 != 0: # if the number of degrees is odd
				if i >= (Npop - m): 
					contact = [position[(i+x)-Npop] for x in range(1, m+1)] 
				else: 
					contact = [position[i+x] for x in range(1, m+1)] 
				opposite = int(len(position)/2)
				if i < int(Npop/2): 
					contact += [position[i+opposite]]
			else: # when number of degrees is even
				if i >= (Npop - m): 
					contact = [position[(i+x)-Npop] for x in range(1, m+1)] 
				else: 
					contact = [position[i+x] for x in range(1, m+1)] 
			temp = period_Relation(len(contact), t, time_horizon)
			for y in range(len(temp)): 
				temp[y]['existing'] = 0
			temp_rel_dict[focalID].update({contact[x]: temp[x] for x in range(len(temp))})
			for x in range(len(contact)): 
				temp_rel_dict[contact[x]].update(copy.deepcopy({focalID: temp[x]}))

		out_rel_dict[t] = temp_rel_dict
		total_links = sum([len(val) for key, val in temp_rel_dict.items()])
		# print(existing_links)
		sum_exist.append(existing_links/total_links)
	return out_rel_dict


def small_world_generator(node, Ndegree, plDistMap, time_horizon, t_end = 1, p_rewire = 0.3): 
	# creating 5 years of annual networkss
	out_rel_dict = dict([(key, {}) for key in range(1, t_end + 1)])
	sum_exist = []
	Npop = len(node)

	for t in range(1, t_end + 1): 
		temp_rel_dict = dict([(key, {}) for key in node])
		existing_links = 0

		# find the relationships that overlap between year t-1 and year t
		if t > 1: 
			temp_for_existing = copy.deepcopy(out_rel_dict[t-1])	
			for i, v in temp_for_existing.items(): 
				for i2, v2 in v.items(): 
					temp_for_existing[i][i2]["existing"] = 1
			for i, v in temp_for_existing.items(): 
				temp_rel_dict[i].update({key: val for key, val in v.items() if val["end"] >= t*12}) 
			existing_links = sum([len(val) for key, val in temp_rel_dict.items()])

		position = np.random.permutation(node).tolist()
		# position = node
		m = int(Ndegree/2) # m neighbors
		rewire_dict = dict([(key, []) for key in node])
		all_dict = dict([(key, []) for key in node])
		for i in range(len(position)): 
			focalID = position[i]
			if Ndegree % 2 != 0: # if the number of degrees is odd
				if i >= (Npop - m): 
					contact = [position[(i+x)-Npop] for x in range(1, m+1)] 
				else: 
					contact = [position[i+x] for x in range(1, m+1)] 
				contact_left = [position[(i-x)] for x in range(1, m+1)] 
				opposite = int(len(position)/2)
				if i < int(Npop/2): 
					contact += [position[i+opposite]]
				else: 
					contact += [position[i-opposite]]
				contact_all = contact + contact_left
			else: # when number of degrees is even
				if i >= (Npop - m): 
					contact = [position[(i+x)-Npop] for x in range(1, m+1)] 
				else: 
					contact = [position[i+x] for x in range(1, m+1)] 
				contact_left = [position[(i-x)] for x in range(1, m+1)] 
				contact_all = contact + contact_left
			rewire_dict[focalID].extend(contact)
			all_dict[focalID].extend(contact_all)

		for k, v in rewire_dict.items():
			rewire = [v[x] for x in range(len(v)) if np.random.binomial(1, p = p_rewire, size = 1) == 1]
			temp_contact = all_dict[k]
			in_market = list(set(node) - set(all_dict[k]+[k]))
			new_contact = np.random.choice(in_market, len(rewire)).tolist()
			contact = list(set(temp_contact + new_contact) - set(rewire))
			temp = period_Relation(len(contact), t, time_horizon)
			for y in range(len(temp)): 
				temp[y]['existing'] = 0
			temp_rel_dict[k].update({contact[x]: temp[x] for x in range(len(temp))})
			for x in range(len(contact)): 
				temp_rel_dict[contact[x]].update(copy.deepcopy({k: temp[x]}))

		out_rel_dict[t] = temp_rel_dict
		total_links = sum([len(val) for key, val in temp_rel_dict.items()])
		# print(existing_links)
		sum_exist.append(existing_links/total_links)
	return out_rel_dict


def random_graph_generator(node, Ndegree, plDistMap, node_cluster, time_horizon, t_end = 1): 
	# creating 5 years of annual networkss
	Npop = len(node)
	p_tie = ((Ndegree*Ndegree)/(Ndegree*Npop))
	out_rel_dict = dict([(key, {}) for key in range(1, t_end + 1)])
	sum_exist = []
	for t in range(1, t_end + 1): 
		temp_rel_dict = dict([(key, {}) for key in node])
		existing_links = 0
		p_tie2 = p_tie
		# find the relationships that overlap between year t-1 and year t
		if t > 1: 
			temp_for_existing = copy.deepcopy(out_rel_dict[t-1])	
			for i, v in temp_for_existing.items(): 
				for i2, v2 in v.items(): 
					temp_for_existing[i][i2]["existing"] = 1
			for i, v in temp_for_existing.items(): 
				temp_rel_dict[i].update({key: val for key, val in v.items() if val["end"] >= t*12}) 
			existing_links = sum([len(val) for key, val in temp_rel_dict.items()])
			p_tie2 = (Ndegree*Npop - existing_links)/(Npop*Npop)
		
		for i in node: 
			'''
			if t > 1: 
				existing_contact = [key for key, val in temp_rel_dict[i].items()]
			else: 
				existing_contact = []
			'''
			existing_contact = []
			temp1 = np.array(node[i:])
			temp1 = np.setdiff1d(temp1, existing_contact)
			# p_tie2 = (Ndegree-len(existing_contact))/(Npop-len(existing_contact))
			if (len(temp1) > 0): 
				temp2 = np.random.rand(len(temp1)) > (1-p_tie2)
				contact = temp1[temp2].tolist()
			else: 
				contact = []
			temp = period_Relation(len(contact), t, time_horizon)
			for y in range(len(temp)): 
				temp[y]['existing'] = 0
			temp_rel_dict[i].update({contact[x]: temp[x] for x in range(len(temp))})
			for x in range(len(contact)):	
				temp_rel_dict[contact[x]].update(copy.deepcopy({i: temp[x]}))

		out_rel_dict[t] = temp_rel_dict
		total_links = sum([len(val) for key, val in temp_rel_dict.items()])
		sum_exist.append(existing_links/total_links)
	return out_rel_dict


def powerLaw_graph_generator(node, Ndegree, plDistMap, node_cluster, time_horizon, t_end = 1): 
	# creating 5 years of annual networkss
	Npop = len(node)
	out_rel_dict = dict([(key, {}) for key in range(1, t_end + 1)])
	sum_exist = []
	for t in range(1, t_end + 1): 
		temp_rel_dict = dict([(key, {}) for key in node])
		existing_links = 0
		distr = [val for key, val in plDistMap.items()]
		key_contact = [key for key, val in plDistMap.items()]
		temp_contact = np.random.choice(key_contact, p = distr, replace = True, size = Npop).tolist()
		node_contact = dict(zip(node, temp_contact))
		# find the relationships that overlap between year t-1 and year t
		if t > 1: 
			temp_for_existing = copy.deepcopy(out_rel_dict[t-1])	
			for i, v in temp_for_existing.items(): 
				for i2, v2 in v.items(): 
					temp_for_existing[i][i2]["existing"] = 1
			for i, v in temp_for_existing.items(): 
				temp_rel_dict[i].update({key: val for key, val in v.items() if val["end"] >= t*12}) 
			existing_links = sum([len(val) for key, val in temp_rel_dict.items()])

		sort_node = [y for x,y in sorted(zip(temp_contact,node), reverse = True) if x > 0]

		for i in range(len(sort_node)): 
			'''
			if t > 1: 
				existing_contact = [key for key, val in temp_rel_dict[i].items()]
			else: 
				existing_contact = []
			'''
			focalID = sort_node[i]
			temp1 = np.array(sort_node[(i+1):])
			temp_node = [key for key, val in node_contact.items() if val <= 0]
			temp1 = np.setdiff1d(temp1, temp_node)
			n_need = node_contact[focalID]
			# temp1 = np.setdiff1d(temp1, existing_contact)
			# p_tie2 = (Ndegree-len(existing_contact))/(Npop-len(existing_contact))
			if (len(temp1) > n_need): 
				contact = np.random.choice(temp1, replace = False, size = n_need).tolist()
			elif (len(temp1) < n_need) & (len(temp1) > 0): 
				contact = temp1
			else: 
				contact = []
			temp = period_Relation(len(contact), t, time_horizon)
			for y in range(len(temp)): 
				temp[y]['existing'] = 0
			temp_rel_dict[focalID].update({contact[x]: temp[x] for x in range(len(temp))})
			node_contact[focalID] = node_contact[focalID] - len(contact)
			for x in range(len(contact)):	
				temp_rel_dict[contact[x]].update(copy.deepcopy({focalID: temp[x]}))
				node_contact[contact[x]] = node_contact[contact[x]] - 1

		# check leftovers
		left_overs = [key for key, val in node_contact.items() if val != 0]
		if len(left_overs) > 0: 
			for i in left_overs: 
				n_need = node_contact[i]
				existing = [key for key, val in temp_rel_dict[i].items()]
				temp_select = list(set(node) - set(existing))
				contact = np.random.choice(temp_select, replace = False, size = n_need).tolist()
			temp = period_Relation(len(contact), t, time_horizon)
			for y in range(len(temp)): 
				temp[y]['existing'] = 0
			temp_rel_dict[focalID].update({contact[x]: temp[x] for x in range(len(temp))})
			for x in range(len(contact)):	
				temp_rel_dict[contact[x]].update(copy.deepcopy({focalID: temp[x]}))

	out_rel_dict[t] = temp_rel_dict
	# total_links = np.mean([len(val) for key, val in temp_rel_dict.items()])
	return out_rel_dict


def community_graph_generator(node, Ndegree, plDistMap, node_cluster, time_horizon, t_end = 1): 
	# creating 5 years of annual networks
	Npop = len(node)
	n_nodes_in_cluster = {key: len([x for x, v in node_cluster.items() if v == key]) for key in range(1, 6)}
	pCluster = 0.99
	cluster_p = {key: [Ndegree*pCluster/(n_nodes_in_cluster[key]-1), Ndegree*(1-pCluster)/(Npop-n_nodes_in_cluster[key]-1)] for key in range(1, 6)}
	out_rel_dict = dict([(key, {}) for key in range(1, t_end + 1)])
	sum_exist = []
	for t in range(1, t_end + 1): 
		temp_rel_dict = dict([(key, {}) for key in node])

		for i in node: 
			temp1 = np.array(node[i:])
			# p_tie2 = (Ndegree-len(existing_contact))/(Npop-len(existing_contact))
			if (len(temp1) > 0): 
				temp_p = [cluster_p[node_cluster[i]][0] if node_cluster[x] == node_cluster[i] else cluster_p[node_cluster[i]][1] for x in temp1]
				temp2 = np.random.binomial(1, p = temp_p, size = len(temp1))
				contact = temp1[temp2==1].tolist()
			else: 
				contact = []
			temp = period_Relation(len(contact), t, time_horizon)
			temp_rel_dict[i].update({contact[x]: temp[x] for x in range(len(temp))})
			for x in range(len(contact)):	
				temp_rel_dict[contact[x]].update(copy.deepcopy({i: temp[x]}))

		out_rel_dict[t] = temp_rel_dict
		total_links = sum([len(val) for key, val in temp_rel_dict.items()])
		'''
		# check if clusters are formed
		test = {key1 : [key2 for key2, val2 in val1.items()] for key1, val1 in temp_rel_dict.items()}
		same_cluster = {key: [1 if node_cluster[x] == node_cluster[key] else 0 for x in val] for key, val in test.items()}
		same_cluster = np.mean([sum(val)/len(val) for key, val in same_cluster.items()])
		'''
	return out_rel_dict



# graph summary
def annual_G_summary(annual_rel_dict, g): 
	# the input has to be networkx object
	G = nx.Graph(annual_rel_dict[g])
	Npop = len(G.node)
	node_degree = dict(G.degree())
	degrees = [val for key, val in node_degree.items()]
	avg_degree = np.mean(degrees)
	var_degree = np.var(degrees)
	degree_dist = {i: degrees.count(i)/Npop for i in set(degrees)}
	prop_isolates = len([x for x in degrees if x == 0])/Npop
	Gc = max(nx.connected_component_subgraphs(G), key=len)
	prop_in_Gc = len(Gc.node())/Npop
	avg_path = nx.average_shortest_path_length(G)

	return {"prop_isolates": prop_isolates, "avg_degree": avg_degree, "var_degree": var_degree, 
		"prop_in_Gc":prop_in_Gc, "avg_path":avg_path, "degree_dist": degree_dist}


def monthly_degree_dist(rel_hist, Npop, t): 
	G = nx.Graph(rel_hist[t])
	node_degree = dict(G.degree())
	degrees = [val for key, val in node_degree.items()]
	temp_dist = {i: degrees.count(i)/Npop for i in set(degrees)}
	temp_key = [key for key, val in temp_dist.items()]
	out = {i: temp_dist[i] if i in temp_key else 0 for i in range(0, 21)}
	out[0] = 1-sum([val for key, val in temp_dist.items()])
	out[20] = sum([val for key, val in temp_dist.items() if key >= 20])
	return out


def pert(n, x_min, x_max, x_mode, lam = 4): 
	x_range = x_max-x_min
	if x_range == 0: 
		np.repeat(x_min, n)
	mu = ( x_min + x_max + lam * x_mode ) / ( lam + 2 )
	if mu == x_mode: 
		v = (lam/2) + 1
	else: 
		v = ((mu-x_min)*(2*x_mode-x_min-x_max))/(( x_mode - mu ) * ( x_max - x_min ))
	w = (v*(x_max - mu))/(mu-x_min)
	return stats.beta.rvs(v, w, size = n)*x_range + x_min

####################################################################

def SIR_net_generator(run, graph_function, Npop = 1000, Ndegree = 3, time_horizon = 12*5, pInf = 0.17, pCondom = 0.5, 
	redCondom = 0.6, durI = 12, rScr = 0.3/12, pContact_tr = 0.8, pContact_ept = 0.8, pContact_PN = 0.8, 
	p_treat_tr = 0.8, p_treat_ept = 0.8, p_treat_PN = 0.8, 
	init_prev = 0.05, n_cluster = 5, strategy = "contact tracing_degree", 
	max_contact = 50, max_ept = 500, alpha = 1, check_steady_state = False): 
	'''
	Npop = 5000
	Ndegree = 4*5
	time_horizon = 12*5
	pInf = 0.135
	run = np.random.choice(list(range(1, 1001)), 1)
	# pCondom = 0.5
	pCondom = 0.44
	redCondom = 0.6
	durI = 6
	rScr = 0.3/12
	pContact = 0.1
	init_prev = 0.1
	n_cluster = 5
	graph_function = random_graph_generator
	t_end = 1
	strategy = "null" 
	# 4 strategies: do nothing, EPT, contact tracing_degree (contact high degree nodes first), contact tracing_chronology (first come, first serve.)
	pContact_tr = 0.70 # this is prob of contact among current partners
	pContact_ept = 0.70 # this is prob of contact among current partners
	pContact_PN = 0.49 # this is prob of contact among current partners
	p_treat_ept = 0.79
	p_treat_tr = 0.79
	p_treat_PN = 0.71
	max_contact = 30 # maximum of contact tracing per month for the public health officials
	max_ept = 8 # maximum packs of ept delivery per person
	alpha = 0 
	'''

	


	np.random.seed(run)

	init_inf = int(Npop*init_prev)
	rel_hist = dict([(key, []) for key in range(1, time_horizon+1)])
	attr_hist = dict([(key, []) for key in range(0, time_horizon+1)])
	inf_hist = dict([(key, []) for key in range(1, time_horizon+1)])

	cMedicine = np.mean([46, 39, 45, 45, 97, 86, 51, 56]) # cost of a medicine pack (Owusu-Edusei et al. 2013)
	cInvestigate = 120 # cost of contact tracing (Armbruster and Brandeau)
	cTest = np.mean([117, 110, 70, 70, 183, 122, 70, 70]) # cost of STD exam/clinical visits (Owusu-Edusei et al. 2013)
	# q = 0.9 # multiplier of the utility of the infected (Armbruster and Brandeau)
	q = 0.99 
	discount_rate = 0.03/12

	pRec = 1-np.exp(-1/durI)

	ID = list(range(1, Npop+1))
	S = [1]*Npop
	I = [0]*Npop
	T = [0]*Npop # this state is only for recording time of treatment
	Npartner = [0]*Npop
	attr_df = {ID[x]: {"S": S[x], "I": I[x], "T": T[x], "Npartner": Npartner[x]} for x in range(len(ID))}
	for key, val in attr_df.items(): 
		attr_df[key].update({"time": 0})

	node = ID
	node_cluster = {key: int((key-1)/(Npop/n_cluster)) + 1 for key in node}
	init_select = [key for key, val in node_cluster.items() if val == 1]

	infID = list(np.random.choice(init_select, init_inf, replace = False))

	for x in infID: 
		attr_df[x]["S"] = 0
		attr_df[x]["I"] = 1

	attr_hist[0] = copy.deepcopy(attr_df)
	bbb = timeit.default_timer()

	out_sum = {}
	out_sum["time"] = [0]
	out_sum["S"] = [sum([val["S"] for key, val in attr_df.items()])/Npop]
	out_sum["I"] = [sum([val["I"] for key, val in attr_df.items()])/Npop]
	out_sum["newI"] = [0]
	out_sum["newT"] = [0]
	out_sum["nDeliver"] = [0]
	out_sum["nOvertreat"] = [0]
	out_sum["nInfTreatIntervention"] = [0]
	out_sum["nInvestigate"] = [0]
	out_sum['nNotified'] = [0]
	out_sum["nTested"] = [0]
	out_sum['avg_degree'] = [0]

	out_sum['CostMedicine'] = [0]
	out_sum['CostTracing'] = [0]
	out_sum['CostTest'] = [0]

	out_sum['Util'] = [0]

	# aaa = timeit.default_timer()
	# annual_rel_dict, p_existing = graph_function(node, Ndegree)
	annual_rel_dict = graph_function(node= node, Ndegree=Ndegree, plDistMap = plDistMap, node_cluster = node_cluster, time_horizon = time_horizon, t_end = 1)
	# print(timeit.default_timer() - aaa)

	original_name_ls = []
	tracing_ls = []

	if isinstance(p_treat_ept, dict): 
		testEPT_vec = pert(Npop, p_treat_ept['min'], p_treat_ept['max'], p_treat_ept['mean'], lam = 4)
		testTR_vec = testEPT_vec
		temp = pert(Npop, p_treat_PN['min'], p_treat_PN['max'], p_treat_PN['mean'], lam = 4)
		testPN_vec = (temp<testEPT_vec)*temp + (temp>=testEPT_vec)*testEPT_vec
	else: 
		testEPT_vec = np.repeat(p_treat_ept, Npop)
		testTR_vec = np.repeat(p_treat_tr, Npop)
		testPN_vec = np.repeat(p_treat_PN, Npop)

	aaa = timeit.default_timer()
	for t in range(0, time_horizon): 
	# for t in range(0, 10): 
		# preparing relation data at one time step
		# print(t)
		# t = 50
		temp_annual_rel = copy.deepcopy(annual_rel_dict[1])
		# aaa =timeit.default_timer()
		actor1, actor2 = zip(*[(k, key) for k, v in temp_annual_rel.items() for key, val in v.items() if (val["begin"] <= t) & (val["end"] > t)])
		rel_dict = dict([(key, {}) for key in set(actor1)])
		for x in range(len(actor1)): 
			rel_dict[actor1[x]].update({actor2[x]: temp_annual_rel[actor1[x]][actor2[x]]})
			rel_dict[actor1[x]][actor2[x]]["infection"] = 0

		infID = [key for key, val in attr_df.items() if val['I'] == 1]
		S_ID = [key for key, val in attr_df.items() if val['S'] == 1]
		inf_actor = list(set(actor1+actor2).intersection(set(infID)))
		new_infID = []

		for x in inf_actor: 
			temp = [key for key, val in rel_dict[x].items()]
			temp = list(set(temp).intersection(set(S_ID)))
			freq = np.random.poisson(lam = 27/12, size = len(temp)) # we only sample the frequence of sex for the discordant couples to calculate infection
			inf_or_not = np.random.binomial(1, p = 1-(1-pInf*(pCondom*(1-redCondom)+(1-pCondom)))**freq).tolist() 
			for y in range(len(temp)): 
				rel_dict[x][temp[y]].update({"infection":inf_or_not[y]})
				# infection is directional
			new_infID += [temp[y] for y in range(len(temp)) if inf_or_not[y] == 1]
		new_infID = list(set(new_infID) - set(infID))

		rel_hist[t+1] = rel_dict

		# print(timeit.default_timer() - aaa)
		###################################################
		# if t >= 36:  
		if t >= (time_horizon - 12*2):  
			# infected ID who get treated
			test_ls = [x for x in range(len(ID)) if np.random.binomial(1, p = rScr, size = 1) == 1]
			screen_ls = list(set(test_ls).intersection(set(infID)))
			# print(screen_ls)
			treat_ls = screen_ls
			contact_investigate = []
			contact_notified = []
			overtreat = []
			deliver_ls = []
			InfTreatIntervention = []

			# print("==== before tracing", contact_treat)

			if strategy == "contact tracing_degree": 
				tempID = copy.deepcopy(screen_ls)
				temp_name = {key: {k: t-v['end'] if v['end'] < t else 0} for key, val in temp_annual_rel.items() if key in tempID for k, v in val.items() if (v['end'] >= t-6) & (v['begin'] < t)}
				temp = {key0: [key1 for key1, val1 in val0.items() if np.random.binomial(1, p = pContact_tr*(np.exp(-alpha*val1)), size = 1) == 1] for key0, val0 in temp_name.items()}
				temp = [val for key, val in temp.items() if len(val) > 0]
				temp_contact = list(set([x for y in temp for x in y])) # this is just for collecting names so it includes those who are uninfected 
				# contact tracing at most max_contact individuals in the population
				contact_investigate = tracing_ls[:(max_contact)] # this is for the cost
				original_name_ls = [original_name_ls[x] for x in range(len(original_name_ls)) if original_name_ls[x] not in contact_investigate] # remove those who were investigated from the original_name_ls
				temp_name = list(set(contact_investigate) - set(treat_ls)) # dropped those who are treated at this time step because they are not going to come in anyways
				temp = np.random.binomial(1, p = testTR_vec[[x-1 for x in temp_name]], size = len(temp_name)).tolist() # for those who are not treated yet, they could come in to be tested with p_treat_tr
				contact_treat = [temp_name[x] for x in range(len(temp_name)) if temp[x] == 1] # this is those who come in to be tested
				test_ls += contact_treat
				contact_treat = list(set(contact_treat).intersection(set(infID))) # those who are tested positive through contact tracing
				treat_ls += contact_treat
				# only collect names of the partners of those who are positive 
				temp_name = {key: {k: t-v['end'] if v['end'] < t else 0} for key, val in temp_annual_rel.items() if key in contact_treat for k, v in val.items() if (v['end'] >= t-6) & (v['begin'] < t)}
				temp = {key0: [key1 for key1, val1 in val0.items() if np.random.binomial(1, p = pContact_tr*(np.exp(-alpha*val1)), size = 1) == 1] for key0, val0 in temp_name.items()}
				temp = [val for key, val in temp.items() if len(val) > 0]
				temp_contact += list(set([x for y in temp for x in y])) # this is just for collecting names so it includes those who are uninfected 
				# print(temp_contact)
				original_name_ls += temp_contact
				original_name_ls = [original_name_ls[x] for x in range(len(original_name_ls)) if original_name_ls[x] not in treat_ls]
				temp = {x: original_name_ls.count(x) for x in original_name_ls}
				tracing_ls = sorted(temp, key=temp.get, reverse=True)
				InfTreatIntervention += contact_treat
			elif strategy == "contact tracing_chronology": 
				tempID = copy.deepcopy(screen_ls)
				temp_name = {key: {k: t-v['end'] if v['end'] < t else 0} for key, val in temp_annual_rel.items() if key in tempID for k, v in val.items() if (v['end'] >= t-6) & (v['begin'] < t)}
				temp = {key0: [key1 for key1, val1 in val0.items() if np.random.binomial(1, p = pContact_tr*(np.exp(-alpha*val1)), size = 1) == 1] for key0, val0 in temp_name.items()}
				temp = [val for key, val in temp.items() if len(val) > 0]
				temp_contact = list(set([x for y in temp for x in y])) # this is just for collecting names so it includes those who are uninfected 
				# contact tracing at most max_contact individuals in the population
				contact_investigate = tracing_ls[:(max_contact)] # this is for the cost
				original_name_ls = [original_name_ls[x] for x in range(len(original_name_ls)) if original_name_ls[x] not in contact_investigate]
				temp_name = list(set(contact_investigate) - set(treat_ls)) # dropped those who are treated at this time step because they are not going to come in anyways
				temp = np.random.binomial(1, p = testTR_vec[[x-1 for x in temp_name]], size = len(temp_name)).tolist() # for those who are not treated yet, they could come in to be tested with p_treat_tr
				contact_treat = [temp_name[x] for x in range(len(temp_name)) if temp[x] == 1] # this is those who come in to be tested
				test_ls += contact_treat
				contact_treat = list(set(contact_treat).intersection(set(infID))) # those who are tested positive through contact tracing
				treat_ls += contact_treat
				# only collect names of the partners of those who are positive 
				temp_name = {key: {k: t-v['end'] if v['end'] < t else 0} for key, val in temp_annual_rel.items() if key in contact_treat for k, v in val.items() if (v['end'] >= t-6) & (v['begin'] < t)}
				temp = {key0: [key1 for key1, val1 in val0.items() if np.random.binomial(1, p = pContact_tr*(np.exp(-alpha*val1)), size = 1) == 1] for key0, val0 in temp_name.items()}
				temp = [val for key, val in temp.items() if len(val) > 0]
				temp_contact += list(set([x for y in temp for x in y])) # this is just for collecting names so it includes those who are uninfected 
				temp_contact = list(set(temp_contact))
				temp_contact = [temp_contact[x] for x in range(len(temp_contact)) if temp_contact[x] not in original_name_ls]
				original_name_ls += temp_contact
				original_name_ls = [original_name_ls[x] for x in range(len(original_name_ls)) if original_name_ls[x] not in treat_ls]
				tracing_ls = copy.deepcopy(original_name_ls)
				InfTreatIntervention += contact_treat
			elif strategy == "EPT": 
				tempID = copy.deepcopy(screen_ls)
				temp_name = {key: {k: t-v['end'] if v['end'] < t else 0} for key, val in temp_annual_rel.items() if key in tempID for k, v in val.items() if (v['end'] >= t-6) & (v['begin'] < t)}
				temp = {key0: [key1 for key1, val1 in val0.items() if np.random.binomial(1, p = pContact_ept*(np.exp(-val1)), size = 1) == 1] for key0, val0 in temp_name.items()}
				temp_deliver = {key: val if len(val) <= max_ept else np.random.choice(val, max_ept, replace = False).tolist() for key, val in temp.items()}
				temp_deliver = [val for key, val in temp_deliver.items() if len(val) > 0] # individuals who got the medical packs
				deliver_ls = list(set([x for y in temp_deliver for x in y]))
				temp = np.random.binomial(1, p = testEPT_vec[[x-1 for x in deliver_ls]], size = len(deliver_ls)).tolist()
				temp_take = [deliver_ls[x] for x in range(len(deliver_ls)) if temp[x] == 1]
				temp_take = list(set([temp_take[x] for x in range(len(temp_take)) if temp_take[x] not in treat_ls]))
				deliver_treat = list(set(temp_take).intersection(set(infID)))
				treat_ls += deliver_treat
				overtreat += list(set(temp_take) - set(deliver_treat))
				InfTreatIntervention += deliver_treat
			elif strategy == "PN": 
				tempID = copy.deepcopy(screen_ls)
				while len(tempID) > 0: 
					# print(tempID)
					temp_name = {key: {k: t-v['end'] if v['end'] < t else 0} for key, val in temp_annual_rel.items() if key in tempID for k, v in val.items() if (v['end'] >= t-6) & (v['begin'] < t)}
					temp = {key0: [key1 for key1, val1 in val0.items() if np.random.binomial(1, p = pContact_PN*(np.exp(-alpha*val1)), size = 1) == 1] for key0, val0 in temp_name.items()}
					# print(temp)
					temp_PN = {key: val if len(val) <= 30 else np.random.choice(val, 30, replace = False).tolist() for key, val in temp.items()} # 30 is the maximum number of partners that you can contact
					temp_PN = [val for key, val in temp_PN.items() if len(val) > 0] 
					# print(temp_PN)
					PN_ls = [x for y in temp_PN for x in y] # individuals who are notified
					temp = np.random.binomial(1, p = testPN_vec[[x-1 for x in PN_ls]], size = len(PN_ls)).tolist() # sample those who get tested p_treat_PN
					temp_test = [PN_ls[x] for x in range(len(PN_ls)) if temp[x] == 1] 
					temp_test = list(set([temp_test[x] for x in range(len(temp_test)) if temp_test[x] not in test_ls])) # individuals who are tested
					test_pos = list(set(temp_test).intersection(set(infID)))
					treat_ls += test_pos
					test_ls += temp_test
					tempID = copy.deepcopy(test_pos)
					InfTreatIntervention += test_pos
					contact_notified += PN_ls
				# print(contact_notified)
				# print("==================")
			# print("==== after tracing", contact_treat)

			for key in treat_ls: 
				attr_df[key]['I'] = 0
				attr_df[key]['S'] = 1

			for key in treat_ls + overtreat: 
				attr_df[key]['T'] = 1 # this is just for treatment record 
		else: 
			test_ls = []
			treat_ls = []
			contact_investigate = []
			contact_notified = []
			overtreat = []
			deliver_ls = []
			InfTreatIntervention = []

		###################################################
		treat_ls = list(set(treat_ls))
		contact_investigate = list(set(contact_investigate))
		test_ls = list(set(test_ls))

		# spontaneous recovered ID
		infID = list(set(infID) - set(treat_ls))
		if len(infID) > 0: 
			temp = np.random.binomial(1, p = pRec, size = len(infID)).tolist()
			new_recID = [infID[x] for x in range(len(infID)) if temp[x] == 1]
			if len(new_recID) > 0: 
				for key in new_recID: 
					attr_df[key]['I'] = 0
					attr_df[key]['S'] = 1

		# update new infected in the attr_df
		if len(new_infID) > 0: 
			for key in new_infID: 
				attr_df[key]['S'] = 0
				attr_df[key]['I'] = 1

		# calculating number of partners
		temp = {key: len(val) for key, val in rel_dict.items()}
		for key, val in attr_df.items(): 
			attr_df[key]["Npartner"] = 0
			attr_df[key].update({"time": t+1})
		for key, val in temp.items(): 
			attr_df[key]["Npartner"] = temp[key]

		attr_hist[t+1] = copy.deepcopy(attr_df)
		# print(timeit.default_timer()-aaa)
		###################################################

		out_sum["time"] += [t+1]
		out_sum["S"] += [sum([val["S"] for key, val in attr_df.items()])/Npop]
		out_sum["I"] += [sum([val["I"] for key, val in attr_df.items()])/Npop]
		out_sum["newI"] += [len(new_infID)]
		out_sum["newT"] += [len(treat_ls)]
		out_sum["nInfTreatIntervention"] += [len(InfTreatIntervention)] # number of infected treated due to intervention. 
		out_sum["nInvestigate"] += [len(contact_investigate)] 
		out_sum["nNotified"] += [len(contact_notified)]
		out_sum["nDeliver"] += [len(deliver_ls)]
		out_sum["nOvertreat"] += [len(overtreat)]
		out_sum["nTested"] += [len(test_ls)]
		out_sum['avg_degree'] += [sum([val["Npartner"] for key, val in attr_df.items()])/Npop]

		temp = out_sum['nDeliver'][t+1] - (out_sum["nOvertreat"][t+1] + out_sum["nInfTreatIntervention"][t+1]) if out_sum['nDeliver'][t+1] == 0 else out_sum['nDeliver'][t+1]
		out_sum['CostMedicine'] += [(out_sum['newT'][t+1] + out_sum['nOvertreat'][t+1] + temp)*(cMedicine*(1/(1+discount_rate))**(t+1))]
		out_sum['CostTracing'] += [out_sum['nInvestigate'][t+1]*(cInvestigate*(1/(1+discount_rate))**(t+1))]
		out_sum['CostTest'] += [out_sum['nTested'][t+1]*(cTest*(1/(1+discount_rate))**(t+1))]

		out_sum['Util'] += [(out_sum["S"][t+1]*Npop + q*out_sum["I"][t+1]*Npop)*(1/(1+discount_rate))**(t+1)]

		# print(timeit.default_timer()-aaa)
	# print(timeit.default_timer()-aaa)
	# final trend output 

	sum_all = {}
	# calculate average duration
	dumI = {key2: [val[key2]['I'] for key, val in attr_hist.items() if (key >= (time_horizon - 12*2 + 1)) & (key < (time_horizon + 1))] for key2 in range(1, Npop+1)}
	temp = {key: [dumI[key][i+1] - dumI[key][i] for i in range(len(dumI[key])-1)] for key in range(1, Npop+1)}
	nI = [sum([x == 1 for x in val]) for key, val in temp.items()]
	# find those who had most partners: 
	npart = {key1: len([key2 for key2, val2 in val1.items()]) for key1, val1 in annual_rel_dict[1].items()}
	npart = sorted(npart, key=lambda k: npart[k], reverse = True)
	idx = [npart[i] - 1 for i in range(0, 11)]
	n_inf10 = np.mean([nI[i] for i in idx])
	# for dealing with the censoring issue of the duration of infection 
	for key in range(1, 1001): 
		if (dumI[key][-1] == 1) & (0 in dumI[key]): 
			# print(dumI[key])
			# detecting the index of last 0 in the index and find the index of "1" next to the last 0
			# idx = (len(dumI[key]) - dumI[key][::-1].index(0) - 1 ) + 1
			idx = dumI[key][::-1].index(0) 
			# change values after the last 0 
			dumI[key][-idx:] = [0 for i in range(1, (idx+1))]
	temp = {key: [dumI[key][i+1] - dumI[key][i] for i in range(len(dumI[key])-1)] for key in range(1, Npop+1)}
	nI = [sum([x == 1 for x in val]) for key, val in temp.items()]
	timeI = [sum([x == 1 for x in val]) for key, val in dumI.items()]
	avgI_per_person = [x/y for x, y in zip(timeI, nI) if y > 0]

	if len(avgI_per_person) != 0: 
		sum_all['avg_durI'] = sum(avgI_per_person)/len(avgI_per_person)
	else: 
		sum_all['avg_durI'] = float("inf")
	sum_all['prevalence'] = out_sum["I"][time_horizon]
	sum_all['newI'] = sum(out_sum["newI"][(time_horizon - 12*2 + 1):])
	sum_all['newT'] = sum(out_sum["newT"])
	sum_all["nInfTreatIntervention"] = sum(out_sum["nInfTreatIntervention"])
	sum_all['nInvestigate'] = sum(out_sum["nInvestigate"])
	sum_all['nNotified'] = sum(out_sum["nNotified"])
	sum_all["nDeliver"] = sum(out_sum["nDeliver"])
	sum_all["nOvertreat"] = sum(out_sum["nOvertreat"])
	sum_all['ever_infected_node'] = Npop - len([x for x in nI if x == 0])
	sum_all['avg_degree'] = sum(out_sum['avg_degree'][(time_horizon - 12*2 + 1):])/len(out_sum['avg_degree'][(time_horizon - 12*2 + 1):])
	if (strategy == "contact tracing_degree") or (strategy == "contact tracing_chronology"):
		sum_all['treat_per_intervention'] = sum_all['nInfTreatIntervention']/sum_all['nInvestigate'] if sum_all['nInvestigate'] != 0 else float("inf")
	elif strategy == "EPT":
		sum_all['treat_per_intervention'] = sum_all['nInfTreatIntervention']/sum_all['nDeliver'] if sum_all['nDeliver'] != 0 else float("inf")
	elif strategy == "PN": 
		sum_all['treat_per_intervention'] = sum_all['nInfTreatIntervention']/sum_all['nNotified'] if sum_all['nNotified'] != 0 else float("inf")
	else: 
		sum_all['treat_per_intervention'] = float("inf")
	sum_all['avg_num_inf10'] = n_inf10

	sum_all['CostMedicine'] = sum(out_sum["CostMedicine"])
	sum_all['CostTracing'] = sum(out_sum["CostTracing"])
	sum_all['CostTest'] = sum(out_sum["CostTest"])
	sum_all['TotalCost'] = sum_all['CostMedicine'] + sum_all['CostTracing'] + sum_all['CostTest'] 
	sum_all['Util'] = sum(out_sum["Util"][(time_horizon - 12*2 + 1):])


	# graph summary
	G_sum_annual = annual_G_summary(annual_rel_dict, 1)

	# monthly degree distribution
	temp_dist = [monthly_degree_dist(rel_hist, Npop, x) for x in range((time_horizon - 12*2 + 1), (time_horizon + 1))]
	degree_dist = dict([(key, []) for key in range(0, 21)])
	for x in range(len(temp_dist)): 
		for k in range(0, 21):
			degree_dist[k].append(temp_dist[x][k])


	# rel_hist = {key: val for key, val in rel_hist.items() if key in range(49, 61)}
	output_rel_hist = {key1: {val1: {val2: val3['infection'] for val2, val3 in val2.items() } 
		for val1, val2 in val1.items() } 
		for key1, val1 in rel_hist.items()} # 1 means infection happend from key1 to key2
	# attr_hist = {key: val for key, val in attr_hist.items() if key in range(49, 61)}

	print(timeit.default_timer()-bbb)

	# outcomes for plot
	# outcomes = {"EL": output_rel_hist, "annualEL": annual_rel_dict, "node": attr_hist}
	# outcomes = {"run": run, "summary": sum_all, "monthly_avg_degree": out_sum['avg_degree'][37:], 
	# 	"monthly_degree_dist": degree_dist}
	if check_steady_state == True: 
		outcomes = out_sum["I"]
	else: 
		outcomes = {"run": run, "summary": sum_all, "G_sum_annual": G_sum_annual, "monthly_avg_degree": out_sum['avg_degree'][(time_horizon - 12*2 + 1):], 
			"monthly_degree_dist": degree_dist, 'p_treat_ept': p_treat_ept, 'p_treat_PN': p_treat_PN, 'p_treat_tr': p_treat_tr}
	return outcomes


def simulation_wrapper(run): 
	print("run =", run)
	'''
	graph_function = random_graph_generator
	graph_function = community_graph_generator
	graph_function = powerLaw_graph_generator
	'''
	return SIR_net_generator(run, graph_function, 
		Npop = 1000, Ndegree = 4*10, time_horizon = 12*10, 
		pInf = 0.17, pCondom = (0.32+.21)/2, redCondom = 0.6, 
		durI = 6, rScr = 0.3/12, pContact_tr = 0.7, pContact_ept = 0.7, 
		pContact_PN = 0.49, p_treat_tr = 0.79, p_treat_ept = 0.79, p_treat_PN = 0.71, 
		init_prev = 0.05, n_cluster = 5, strategy = "null", max_contact = 30, 
		max_ept = 500, alpha = 1, check_steady_state = True)





'''
import matplotlib as mpl
print(mpl.rcParams['backend'])
mpl.use('TkAgg')
import matplotlib.pyplot as plt
plt.get_backend()
import os
os.chdir("/Users/szu-yukao/Documents/Network_structure_and_STI/networkSTI")
cwd = os.getcwd()
print(cwd)

fig = plt.figure(figsize=(6,4))
xax = np.array([x for x in range(len(out_sum['I']))])
plt.plot(xax, out_sum['I'], color = 'red', linewidth=2)
plt.tight_layout()
plt.savefig('results/trend/test random 5 years.eps', format='eps', dpi=1000)
'''




