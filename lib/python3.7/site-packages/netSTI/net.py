import numpy as np
import networkx as nx 
import pandas as pd 
import copy
import timeit
import operator
import scipy.stats as stats
import netSTI.mydata as data
import netSTI.copula as copula

class MyError(Exception): 
	def __init__(self, arg): 
		self.arg = arg

###################################################################
# common functions

def get_params(unit = 26): 
	return data.Params(unit).pInf, \
	data.Params(unit).pCondom, \
	data.Params(unit).redCondom, \
	data.Params(unit).meanActs, \
	data.Params(unit).pRec, \
	data.Params(unit).max_contact, \
	data.Params(unit).max_ept, \
	data.Params(unit).alpha, \
	data.Params(unit).cMedicine, \
	data.Params(unit).cInvestigate, \
	data.Params(unit).cTest, \
	data.Params(unit).q, \
	data.Params(unit).discount_rate 


def gen_adj_matrix_from_dd(ID, Npop, gen_dd, d_distribution = "random", \
	ID_cluster = None, pCluster = 0.99):

	# keep track of the sexual partnership using adjacency matrix
	tmpMatrix = np.zeros((Npop, Npop))	

	if d_distribution != 'community':
		# counter is to keep track of the number of sex partners while generating sexual contact network
		counter = np.zeros(Npop)

		for i in ID: 
			n_samp = int(gen_dd[i] - counter[i])
			if n_samp > 0: 
				include_set = np.where(gen_dd - counter > 0)[0]		
				include_set = np.setdiff1d(include_set, i)
				has_rel_set = np.where(tmpMatrix[i] == 1)[0]
				include_set = np.setdiff1d(include_set, has_rel_set)
				sampID = np.array([])
				if (include_set.shape[0] > n_samp) & (n_samp > 0): 
					sampID = np.random.choice(include_set, size = n_samp, replace = False)
				if (include_set.shape[0] <= n_samp) & (n_samp > 0): 
					sampID = include_set
				if (n_samp <= 0) & (counter[i] > 0):
					sampID = np.random.choice(ID[ID != i], size = counter, replace = False)

				tmpMatrix[i, sampID] = 1
				tmpMatrix[sampID, i] = 1
				counter[i] += sampID.shape[0]
				counter[sampID] += 1
	else:
		# expected number of partners are outside of the community
		n_out_vec = np.random.binomial(gen_dd.astype(int), p = 1 - pCluster)
		n_in_vec = gen_dd - n_out_vec

		# use counter_out and counter_in to count partners
		counter_out = np.zeros(Npop)
		counter_in = np.zeros(Npop)

		for i in ID: 
			n_samp_out = int(n_out_vec[i] - counter_out[i])
			n_samp_in = int(n_in_vec[i] - counter_in[i])
			dum = (ID_cluster == ID_cluster[i])
			has_rel_set = np.where(tmpMatrix[i] == 1)[0]

			include_in_set = ID[dum]
			include_in_set = include_in_set[(n_in_vec[include_in_set] - counter_in[include_in_set]) > 0]
			include_in_set = np.setdiff1d(include_in_set, i)
			include_in_set = np.setdiff1d(include_in_set, has_rel_set)

			include_out_set = ID[~dum]
			include_out_set = include_out_set[(n_out_vec[include_out_set] - counter_out[include_out_set]) > 0]
			include_out_set = np.setdiff1d(include_out_set, has_rel_set)	

			sampID1 = np.array([]).astype(int)
			if n_samp_in > 0: 
				if include_in_set.shape[0] > n_samp_in:
					sampID1 = np.random.choice(include_in_set, size = n_samp_in, replace = False)
				else: 
					sampID1 = include_in_set

			sampID2 = np.array([]).astype(int)
			if n_samp_out > 0:
				if include_out_set.shape[0] > n_samp_out: 
					sampID2 = np.random.choice(include_out_set, size = n_samp_out, replace = False)
				else: 
					sampID2 = include_out_set

			sampID = np.concatenate((sampID1, sampID2))

			tmpMatrix[i, sampID] = 1
			tmpMatrix[sampID, i] = 1
			counter_in[i] += sampID1.shape[0]
			counter_in[sampID1] += 1	
			counter_out[i] += sampID2.shape[0]
			counter_out[sampID2] += 1	
	return tmpMatrix


def period_Relation(agent_ID, part_ID, avg_dur, time_horizon): 
	''' Assign beginning and end times to each relationship
	
	Arguments: 
	n_rel (integer): # of relaltionships
	dur (numpy vector): a vector of mean duration 
	dur_dist (numpy vector): a vector of distribution of duration. This is a proportion
	time_horizon (integer): number of cycles

	Returns: 
	rel_begin: a vector of beginning time of a relationship
	rel_end: a vector of end time of a relationship
	'''
	tmp_dur = (avg_dur[agent_ID] + avg_dur[part_ID]) / 2

	duration = np.round(np.random.exponential(tmp_dur)).astype(int)

	# the beginning cycle of the relationship could be negative 
	# the tmp vector is the minimum beginning time
	# tmp_lb = 0 - duration
	# vfunc = np.vectorize(np.random.uniform)
	# rel_begin = np.ceil(vfunc(tmp_lb, time_horizon)).astype(int)
	rel_begin = np.random.choice(np.arange(time_horizon), size = duration.shape[0])
	rel_end = rel_begin + duration
	return rel_begin, rel_end


def generate_edge_list_array(sampMatrix, Npop, avg_dur, time_horizon): 
	""" Creating the relationship between individuals using edge list format
	
	Arguments: 
	sampMatrix (numpy array): an array of probability of tie formation in each cell. 
	Npop (integer): Population size. 

	Returns: 
	out_rel (numpy array): an edge list shaped as numpy array with 4 columns. Each row represents 
	a relationship. Column 0 is the ID of partner 1. Column 1 is the ID of partner 2. Column 2
	is the beginning cycle of the relationship. Column 3 is the end cycle of the relationship. 	
	"""
	out_rel = [None] * Npop

	for i in range(sampMatrix.shape[0]): 
		part_ID = np.where((sampMatrix[i] == 1))[0]
		part_ID = part_ID[part_ID > i]
		agent_ID = np.repeat(i, part_ID.shape[0])
		rel_beg = np.array([]).astype(int)
		rel_end = np.array([]).astype(int)
		if agent_ID.shape[0] > 0: 
			rel_beg, rel_end = period_Relation(agent_ID, part_ID, avg_dur, time_horizon = time_horizon)
		out_rel[i] = np.vstack((agent_ID, part_ID, rel_beg, rel_end)).T

	out_rel = np.vstack(out_rel)
	if out_rel.shape[0] != np.sum(sampMatrix) / 2: 
		MyError("row number of the edgelist is different than the sum of adjacency matrix divided by 2")
	return out_rel


def random_graph_generator(ID, Npop, Ndegree, time_horizon, independent = True): 
	"""Generate cumulative random networks
	
	Arguments: 
	ID: a numpy vector of individual IDs.
	Npop (integer): population size 
	Ndegree: an integer indicates the average number of cumulative sex partners that an individual has
	within the time_horizon.
	dur (numpy vector): a vector of mean duration 
	dur_dist (numpy vector): a vector of distribution of duration. This is a proportion
	time_horizon (integer): number of cycles

	Returns: 
	out_rel (numpy array): an edge list shaped as numpy array with 4 columns. Each row represents 
	a relationship. Column 0 is the ID of partner 1. Column 1 is the ID of partner 2. Column 2
	is the beginning cycle of the relationship. Column 3 is the end cycle of the relationship. 

	====
	These are the original code... 
	p_tie = ((Ndegree * Ndegree)/(Ndegree * (Npop - 1))) / 2
	tmpMatrix = np.random.binomial(1, size = (Npop, Npop), p = p_tie)
	tmpMatrix = tmpMatrix + tmpMatrix.T
	tmpMatrix[tmpMatrix > 1] = 1
	np.fill_diagonal(tmpMatrix, 0)

	gen_dd = np.sum(tmpMatrix, 1)
	====
	"""

	cop = copula.CopulaDist(Npop, graph = "random", independent = independent)
	gen_dd = cop.get_degree_poisson(Ndegree)
	gen_avg_dur = cop.get_avg_duration()

	# Get the adjacency matrix
	tmpMatrix = gen_adj_matrix_from_dd(ID, Npop, gen_dd, d_distribution = "random")

	# generate edge list
	out_rel = generate_edge_list_array(tmpMatrix, Npop = Npop, avg_dur = gen_avg_dur, \
		time_horizon = time_horizon)
	return out_rel


def community_graph_generator(ID, Npop, Ndegree, ID_cluster, time_horizon, pCluster = 0.99, independent = True): 
	"""Generate cumulative community structured networks
	
	Arguments: 
	ID: a numpy vector of individual IDs.
	Npop (integer): population size
	Ndegree: an integer indicates the average number of cumulative sex partners that an individual has
	within the time_horizon.
	ID_cluster (numpy array): a vector of cluster ID for each ID. 
	dur (numpy vector): a vector of mean duration 
	dur_dist (numpy vector): a vector of distribution of duration. This is a proportion
	time_horizon (integer): number of cycles
	pCluster (float): the probabilty of assortative matching within the same community 

	Returns: 
	out_rel (numpy array): an edge list shaped as numpy array with 4 columns. Each row represents 
	a relationship. Column 0 is the ID of partner 1. Column 1 is the ID of partner 2. Column 2
	is the beginning cycle of the relationship. Column 3 is the end cycle of the relationship. 

	====
	This are the original code: 
	# calculate the probability of tie formation with individuals in and outside of the community
	p_in_cl = ((Ndegree * pCluster) / (Npop / np.unique(ID_cluster).shape[0] - 1)) / 2
	p_out_cl = ((Ndegree * (1 - pCluster)) / (Npop - (Npop / np.unique(ID_cluster).shape[0]))) / 2

	# making a probability matrix 
	tmpMatrix = np.tile(ID_cluster[:, None], Npop)
	tmpMatrix = (tmpMatrix == tmpMatrix.T)
	tmpMatrix = tmpMatrix * p_in_cl + (1 - tmpMatrix) * p_out_cl
	np.fill_diagonal(tmpMatrix, 0)

	# sample the whether two individuals are sex partners or not
	tmpMatrix = np.random.binomial(1, p = tmpMatrix)
	tmpMatrix = tmpMatrix + tmpMatrix.T
	tmpMatrix[tmpMatrix > 1] = 1
	np.fill_diagonal(tmpMatrix, 0)
	====
	"""
	cop = copula.CopulaDist(Npop, graph = "community", independent = independent)
	gen_dd = cop.get_degree_poisson(Ndegree)
	gen_avg_dur = cop.get_avg_duration()

	# Get the adjacency matrix
	tmpMatrix = gen_adj_matrix_from_dd(ID, Npop, gen_dd, d_distribution = "community", \
		ID_cluster = ID_cluster, pCluster = 0.99)

	# generate edge list
	out_rel = generate_edge_list_array(tmpMatrix, Npop = Npop, avg_dur = gen_avg_dur, \
		time_horizon = time_horizon)
	return out_rel


def power_law_graph_generator(ID, Npop, time_horizon, n_yrs = 10, independent = True): 
	"""Generate cumulative power law networks
	
	Arguments: 
	ID: a numpy vector of individual IDs.
	Npop (integer): population size
	Ndegree: an integer indicates the average number of cumulative sex partners that an individual has
	within the time_horizon.
	dur (numpy vector): a vector of mean duration 
	dur_dist (numpy vector): a vector of distribution of duration. This is a proportion
	time_horizon (integer): number of cycles

	Returns: 
	out_rel (numpy array): an edge list shaped as numpy array with 4 columns. Each row represents 
	a relationship. Column 0 is the ID of partner 1. Column 1 is the ID of partner 2. Column 2
	is the beginning cycle of the relationship. Column 3 is the end cycle of the relationship. 
	"""
	cop = copula.CopulaDist(Npop, graph = "power_law", independent = independent)
	gen_dd = cop.get_degree_power_law()
	gen_avg_dur = cop.get_avg_duration()

	# generate degree sequence for everyone in the population
	ix_sort = np.argsort(-gen_dd)
	gen_dd = gen_dd[ix_sort]
	gen_avg_dur = gen_avg_dur[ix_sort]
	
	tmpMatrix = gen_adj_matrix_from_dd(ID, Npop, gen_dd, d_distribution = "power_law")

	# generate edge list
	out_rel = generate_edge_list_array(tmpMatrix, Npop = Npop, avg_dur = gen_avg_dur, \
		time_horizon = time_horizon)
	return out_rel

def empirical_graph_generator(ID, Npop, time_horizon, n_yrs = 10, independent = True): 
	"""Generate cumulative power law networks
	
	Arguments: 
	ID: a numpy vector of individual IDs.
	Npop (integer): population size
	time_horizon (integer): number of cycles

	Returns: 
	out_rel (numpy array): an edge list shaped as numpy array with 4 columns. Each row represents 
	a relationship. Column 0 is the ID of partner 1. Column 1 is the ID of partner 2. Column 2
	is the beginning cycle of the relationship. Column 3 is the end cycle of the relationship. 
	"""
	cop = copula.CopulaDist(Npop, graph = "empirical", independent = independent)
	gen_dd = cop.get_dd_empirical(n_yrs)
	gen_avg_dur = cop.get_avg_duration()

	# generate degree sequence for everyone in the population
	ix_sort = np.argsort(-gen_dd)
	gen_dd = gen_dd[ix_sort]
	gen_avg_dur = gen_avg_dur[ix_sort]
	
	tmpMatrix = gen_adj_matrix_from_dd(ID, Npop, gen_dd, d_distribution = "power_law")

	# generate edge list
	out_rel = generate_edge_list_array(tmpMatrix, Npop = Npop, avg_dur = gen_avg_dur, \
		time_horizon = time_horizon)
	return out_rel

def get_avg_degree_per_step(rel_hist, Npop, time_horizon): 
	tmp_deg = np.zeros(time_horizon)
	for t in range(time_horizon): 
		tmp_rel = rel_hist[np.where((rel_hist[:, 2] <= t) & (rel_hist[:, 3] >= t))]
		tmp_ix, tmp_n = np.unique(tmp_rel[:, :2], return_counts = True)
		tmp_deg[t] = np.sum(tmp_n) / Npop
	return tmp_deg


def summarize_net_result(rel_hist, Npop, t_begin): 
	# calculate overall degree 
	tmp_ix, tmp_n = np.unique(rel_hist[:, :2], return_counts = True)
	tmp_degree = np.zeros(Npop)
	tmp_degree[tmp_ix] = tmp_n
	mean_deg_all = np.sum(tmp_degree) / Npop

	# calculate correlation between degree and duration
	tmpDur = np.zeros((Npop, Npop))
	tmpDur[:, :] = np.nan
	g_dur = rel_hist[:, 3] - rel_hist[:, 2]
	for i in range(rel_hist.shape[0]): 
		x = rel_hist[i, 0]
		y = rel_hist[i, 1]
		tmpDur[x, y] = g_dur[i]
		tmpDur[y, x] = g_dur[i]
	tmp_dur = np.nanmean(tmpDur, axis = 1)
	tmp_ix = np.isnan(tmp_dur)
	cor = np.round(np.corrcoef(tmp_degree[~tmp_ix], tmp_dur[~tmp_ix])[0, 1], 3)

	# calculate degree over the analysis window
	tmp_ix, tmp_n = np.unique(rel_hist[np.where(rel_hist[:, 3] > t_begin), :2], return_counts = True)
	tmp_degree = np.zeros(Npop)
	tmp_degree[tmp_ix] = tmp_n
	mean_deg_a_window = np.sum(tmp_degree) / Npop

	# calculate the proportion of isolates in the analysis window
	iso_a_window = np.sum(tmp_degree == 0) / Npop
	return {'deg_all': mean_deg_all, 'deg_a_window': mean_deg_a_window, 'iso_a_window': iso_a_window, 'cor': cor}


def get_instantaneous_sex_net(rel_hist, I, T, Npop, t): 
	""" Extract information of the instantaneous sexual network

	Argument:
	rel_hist (numpy array): relationship history
	I (numpy array): a vector of infected status
	T (numpy array): a vector of treated status
	t (integer): time step

	Return: 
	tmp_rel (numpy array): temporary sex relationship at time t
	n_partners (numpy array): modified n_partners, which calculate the current number
	of sex partners at time t
	"""
	n_partners = np.zeros(Npop)
	# 1. get current relationships at time t
	tmp_rel = rel_hist[(rel_hist[:, 2] <= t) & (rel_hist[:, 3] >= t)]
	# 1.1 get # of relationships of the infected
	activeID, tmp_n = np.unique(tmp_rel[:, :2], return_counts = True)
	n_partners[activeID] = tmp_n
	# 2. keep relationships that only have one infected ID
	dum = (I[tmp_rel[:, 0]] + I[tmp_rel[:, 1]]) == 1
	tmp_rel = tmp_rel[dum]
	# 3. keep relationships that no one is on treatment
	dum = (T[tmp_rel[:, 0]] + T[tmp_rel[:, 1]]) == 0
	tmp_rel = tmp_rel[dum]
	return tmp_rel, n_partners

def gen_inf_id_from_external(count_all, Npop, pEFoI, ID_cluster, graph, time_horizon, inf_independent = True): 
	if graph != 'community': 
		if inf_independent == True: 
			tmp_p = Npop * (count_all/np.sum(count_all)) * pEFoI
		else: 
			tmp_p = Npop * (1 / Npop) * np.ones(Npop) * pEFoI
		tmp_p = np.tile(tmp_p, (time_horizon, 1))
		dum = np.random.binomial(1, p = tmp_p)
	else: 
		if inf_independent == True: 
			tmp_count_all = (ID_cluster == 1) * count_all 
			tmp_p = Npop * (tmp_count_all/np.sum(tmp_count_all)) * pEFoI
		else: 
			tmp_p = Npop * (1 / np.sum((ID_cluster == 1))) * (ID_cluster == 1) * pEFoI
		tmp_p = np.tile(tmp_p, (time_horizon, 1))
		dum = np.random.binomial(1, p = tmp_p)
	seed_ix = np.vstack(np.where(dum == 1)).T
	return seed_ix

def make_screening_schedule(rel_hist, time_horizon, Npop, unit_per_year, pScr): 
	tmp_sch = np.zeros((time_horizon, Npop))
	for t in range(time_horizon): 
		tmp_part = np.zeros(Npop)
		# get network of last year, and calculate the number of sex partners in the past 12 months
		tmp_rel = rel_hist[np.where((rel_hist[:, 3] >= (t - unit_per_year + 1)) & (rel_hist[:, 2] <= t))]
		tmp_ix, tmp_n = np.unique(tmp_rel[:, :2], return_counts = True)
		tmp_part[tmp_ix] = tmp_n
		# get a dummy variable indicating whether people were screened in the past year. 
		if (t - unit_per_year) < 0: 
			tmp_begin = 0
		not_yet_scr = (np.sum(tmp_sch[tmp_begin:t], axis = 0) == 0)
		tmp_part = tmp_part * not_yet_scr
		tmp_p = pScr * tmp_part / np.sum(tmp_part) * Npop
		tmp_sch[t] = np.random.binomial(1, p = tmp_p)
	
	# get the screening schedule at each time step
	# column 0 is the time step
	# column 1 is the id that was screened at the time step
	out_sch = np.vstack(np.where(tmp_sch == 1)).T
	return out_sch

def create_tracker_and_outcome_vectors(Npop, time_horizon): 
	# set up output vectors
	S0 = np.ones(Npop)
	I0 = np.zeros(Npop)
	T0 = np.zeros(Npop) # this state is only for recording time of treatment
	person_time0 = np.zeros(Npop)
	n_notification0 = np.zeros(Npop)
	n_name_trace0 = np.zeros(Npop)
	n_infection0 = np.zeros(Npop) # only count new infection in the analysis time (last 10 years)
	n_intervention0 = np.zeros(Npop) # only count new infection in the analysis time (last 10 years)

	out_S0 = np.zeros(time_horizon) # prevalence of S
	out_I0 = np.zeros(time_horizon) # prevalence of I
	out_newI0 = np.zeros(time_horizon)
	out_nDeliver0 = np.zeros(time_horizon)
	out_nContactTrace0 = np.zeros(time_horizon)
	out_nNotified0 = np.zeros(time_horizon)
	out_nTrueTreat0 = np.zeros(time_horizon)
	out_nOvertreat0 = np.zeros(time_horizon)
	out_nTest0 = np.zeros(time_horizon)
	out_nScreen0 = np.zeros(time_horizon)
	out_nTrueTreatIntervention0 = np.zeros(time_horizon)
	out_pEfficient0 = np.zeros(time_horizon)
	out_CostMedicine0 = np.zeros(time_horizon)
	out_CostTracing0 = np.zeros(time_horizon)
	out_CostTest0 = np.zeros(time_horizon)

	return S0, I0, T0, person_time0, n_notification0, n_name_trace0, n_infection0, n_intervention0, \
		out_S0, out_I0, out_newI0, out_nDeliver0, out_nContactTrace0, out_nNotified0, out_nTrueTreat0, \
		out_nOvertreat0, out_nTest0, out_nScreen0, out_nTrueTreatIntervention0, out_pEfficient0, \
		out_CostMedicine0, out_CostTracing0, out_CostTest0


def trans_dynamics(I, tmp_rel, acts, pInf, pCondom, redCondom): 
	infID = np.where(I == 1)[0]
	dum = np.random.binomial(1, \
		p = (1 - (1 - pInf * (pCondom * (1 - redCondom) + (1 - pCondom))) ** acts), 
		size = tmp_rel.shape[0])
	new_infID = np.unique(tmp_rel[dum == 1, :2])
	new_infID = np.setdiff1d(new_infID, infID)
	return infID, new_infID


def notify_contact_deliver_sex_part(tmp_screen_I, rel_hist, unit_per_year, pContact, alpha, t): 
	dum1 = 1 * np.in1d(rel_hist[:, 0], tmp_screen_I)
	dum2 = 1 * np.in1d(rel_hist[:, 1], tmp_screen_I)
	dum = ((dum1 + dum2) == 1)
	screen_rel = rel_hist[dum]
	# get right time period for testing 
	dum = (screen_rel[:, 2] <= t) & ((t - screen_rel[:, 3]) <= (unit_per_year / 2))
	screen_rel = screen_rel[dum]
	tmp = np.round((t - screen_rel[:, 3]) * ((t - screen_rel[:, 3]) >= 0) / 2)
	dum = np.random.binomial(1, p = pContact * (np.exp(-alpha * tmp)), size = screen_rel.shape[0])
	tmp_name, tmp_count = np.unique(screen_rel[dum == 1, :2], return_counts = True)
	dum = ~np.in1d(tmp_name, tmp_screen_I)
	tmp_name = tmp_name[dum]
	tmp_count = tmp_count[dum]
	return tmp_name, tmp_count


def contact_trace_name(n_name_trace, max_contact, tmp_screen_I, p_treat_tr, infID): 
	tmp_name = np.where(n_name_trace > 0)[0]
	if tmp_name.shape[0] > max_contact: 
		tmp_count = n_name_trace[tmp_name]
		tmp_sort = np.argsort(-tmp_count)
		tmp_name = tmp_name[tmp_sort]
		tmp_name = tmp_name[:(max_contact + 1)]
	num_contact = tmp_name.shape[0]
	dum = (np.random.binomial(1, p = p_treat_tr, size = num_contact) == 1)
	trace_test_name = tmp_name[dum]
	# if a partner get tested due to contact tracing, replace the n_name_trace with 0
	n_name_trace[trace_test_name] = 0 
	num_test = trace_test_name.shape[0]
	treat_name = trace_test_name[np.in1d(trace_test_name, infID)]
	tmp_screen_I = np.concatenate((tmp_screen_I, treat_name))
	return tmp_screen_I, tmp_name, n_name_trace, num_contact, num_test, treat_name


def implement_strategy(ID, rel_hist, Npop, time_horizon, unit_per_year, seed_ix, \
	scr_schedule, count_all, out_avg_degree, strategy = 'null', \
	pContact_PN = 0.49, pContact_ept = 0.7, pContact_tr = 0.7, \
	p_treat_PN = 0.71, p_treat_ept = 0.79, p_treat_tr = 0.79): 

	pInf, pCondom, redCondom, acts, pRec, max_contact, max_ept, alpha, \
	cMedicine, cInvestigate, cTest, q, discount_rate = get_params(unit_per_year)

	S, I, T, person_time, n_notification, n_name_trace, n_infection, n_intervention, \
	out_S, out_I, out_newI, out_nDeliver, out_nContactTrace, out_nNotified, out_nTrueTreat, \
	out_nOvertreat, out_nTest, out_nScreen, out_nTrueTreatIntervention, out_pEfficient, \
	out_CostMedicine, out_CostTracing, out_CostTest = create_tracker_and_outcome_vectors(Npop, time_horizon)

	for t in range(0, time_horizon): 
	# for t in range(0, 26): 
		## transmission dynamics
		tmp_rel, n_partners = get_instantaneous_sex_net(rel_hist, I, T, Npop, t)
		infID, new_infID = trans_dynamics(I, tmp_rel, acts, pInf, pCondom, redCondom)
		tmp_seed = seed_ix[seed_ix[:, 0] == t, 1]
		tmp_seed = np.setdiff1d(tmp_seed, infID)

		## Recovered from treated
		treatID = np.where(T == 1)[0]
		T[treatID] = 0
		S[treatID] = 1
		tmp_seed = np.setdiff1d(tmp_seed, treatID)
		new_infID = np.concatenate((new_infID, tmp_seed))

		## screening and testing
		scr_ID = scr_schedule[scr_schedule[:, 0] == t, 1]
		tmp_screen_I = scr_ID[np.in1d(scr_ID, infID)]
		I[tmp_screen_I] = 0
		T[tmp_screen_I] = 1
		S_ID = np.where(S == 1)[0]
		tmp_screen_S = scr_ID[np.in1d(scr_ID, S_ID)]
		out_nScreen[t] = tmp_screen_I.shape[0] + tmp_screen_S.shape[0]	
		out_nTest[t] = tmp_screen_I.shape[0] + tmp_screen_S.shape[0]
		out_nTrueTreat[t] = tmp_screen_I.shape[0]

		# infected ID who get treated
		if strategy == "tracing": 
			tmp_screen_I, contact_name, n_name_trace, num_contact, num_test, treat_name = \
				contact_trace_name(n_name_trace, max_contact, tmp_screen_I, p_treat_tr, infID)
			out_nTrueTreatIntervention[t] = treat_name.shape[0]
			out_nTest[t] += num_test
			n_intervention[contact_name] += 1
			tmp_name, tmp_count = notify_contact_deliver_sex_part(tmp_screen_I, \
				rel_hist, unit_per_year, pContact_tr, alpha, t)
			n_name_trace[tmp_name] += tmp_count
			out_nContactTrace[t] = num_contact
			out_nTrueTreat[t] = tmp_screen_I.shape[0]
			out_pEfficient[t] = out_nTrueTreatIntervention[t] / out_nContactTrace[t - 1]
			I[tmp_screen_I] = 0
			T[tmp_screen_I] = 1

		if strategy == "EPT": 			
			tmp_name, tmp_count = notify_contact_deliver_sex_part(tmp_screen_I, rel_hist, \
				unit_per_year, pContact_ept, alpha, t)
			out_nDeliver[t] = np.sum(tmp_count)
			n_intervention[tmp_name] += 1
			dum = (np.random.binomial(1, p = 1 - (1 - p_treat_ept) ** tmp_count) == 1)
			tmp_name = tmp_name[dum]
			tmp_ept_treat = tmp_name[np.in1d(tmp_name, infID)]
			out_nTrueTreat[t] = tmp_screen_I.shape[0] + tmp_ept_treat.shape[0]
			out_nOvertreat[t] = tmp_name.shape[0] - tmp_ept_treat.shape[0]
			out_nTrueTreatIntervention[t] = tmp_ept_treat.shape[0]
			out_pEfficient[t] = out_nTrueTreatIntervention[t] / out_nDeliver[t]
			tmp_screen_I = np.concatenate((tmp_screen_I, tmp_ept_treat))
			I[tmp_screen_I] = 0
			T[tmp_screen_I] = 1

		if strategy == "PN": 
			if t >= 1: 
				dum = (np.random.binomial(1, p = 1 - (1 - p_treat_PN) ** (n_notification[notify_name])) == 1)
				notify_test_name = notify_name[dum]
				out_nTest[t] += notify_test_name.shape[0]
				notify_true_treat_name = notify_test_name[np.in1d(notify_test_name, infID)]
				out_nTrueTreatIntervention[t] = notify_true_treat_name.shape[0]
				out_pEfficient[t] = out_nTrueTreatIntervention[t] / out_nNotified[t - 1]
				tmp_screen_I = np.concatenate((tmp_screen_I, notify_true_treat_name))
				n_notification[n_notification > 0] = 0

			notify_name, tmp_count = notify_contact_deliver_sex_part(tmp_screen_I, rel_hist, \
				unit_per_year, pContact_PN, alpha, t)
			n_notification[notify_name] += tmp_count
			n_intervention[notify_name] += 1

			out_nNotified[t] = notify_name.shape[0]
			out_nTrueTreat[t] = tmp_screen_I.shape[0]

			I[tmp_screen_I] = 0
			T[tmp_screen_I] = 1
	
		n_infection[new_infID] += 1

		## spontaneous recovered ID
		dum = np.random.binomial(1, p = pRec, size = infID.shape[0]) == 1
		new_recID = infID[dum]
		S[new_recID] = 1
		I[new_recID] = 0

		## updated the health state of the newly infected ID
		S[new_infID] = 0
		I[new_infID] = 1

		person_time += I

		out_S[t] = np.mean(S)
		out_I[t] = np.mean(I)
		out_newI[t] = new_infID.shape[0]

		d_factor = (1 / (1 + discount_rate)) ** (t + 1)
		out_CostMedicine[t] = (out_nTrueTreat[t] + out_nOvertreat[t]) * (cMedicine * d_factor)
		out_CostTracing[t] = out_nContactTrace[t] * (cInvestigate * d_factor)
		out_CostTest[t] = out_nTest[t] * (cTest * d_factor)
	
	n_yrs = time_horizon / unit_per_year
	sum_all = {}
	sum_all["S"] = np.nanmean(out_S)
	sum_all["I"] = np.nanmean(out_I)
	sum_all["newI"] = np.nansum(out_newI)
	sum_all["nDeliver"] = np.nansum(out_nDeliver)
	sum_all["nContactTrace"] = np.nansum(out_nContactTrace)
	sum_all["nNotified"] = np.nansum(out_nNotified)
	sum_all["nTrueTreat"] = np.nansum(out_nTrueTreat)
	sum_all["nOvertreat"] = np.nansum(out_nOvertreat)
	sum_all["nTest"] = np.nansum(out_nTest)
	sum_all["nScreen"] = np.nansum(out_nScreen)
	sum_all["nTrueTreatIntervention"] = np.nansum(out_nTrueTreatIntervention)
	sum_all["pEfficient"] = np.nanmean(out_pEfficient)
	sum_all["pEverInfected"] = np.sum(n_infection > 0) / Npop
	sum_all["averageTimesInfected"] = np.mean(n_infection[n_infection > 0] / n_yrs)
	sum_all["nIntervention"] = np.nansum(n_intervention)
	sum_all["pEverBeenIntervention"] = np.sum(n_intervention > 0) / Npop
	sum_all["avgTimesBeenIntervene"] = np.mean(n_intervention[n_intervention > 0] / n_yrs)
	sum_all["average_person_time"] = np.mean(person_time / n_yrs)
	sum_all["corr_timesInf_and_degree"] = np.round(np.corrcoef(count_all, n_infection)[0, 1], 4)
	sum_all["corr_PT_and_degree"] = np.round(np.corrcoef(count_all, person_time)[0, 1], 4)
	sum_all["CostMedicine"] = np.nansum(out_CostMedicine)
	sum_all["CostTracing"] = np.nansum(out_CostTracing)
	sum_all["CostTest"] = np.nansum(out_CostTest)
	sum_all["TotalCost"] = sum_all["CostMedicine"] + sum_all["CostTracing"] + sum_all["CostTest"]
	return sum_all, out_I


def SIR_net_generator(run, Npop, years = 20, days = 14, 
	graph = "random", pEFoI = (1 / 5000) / 2 , 
	pContact_PN = 0.49, pContact_ept = 0.7, pContact_tr = 0.7, 
	p_treat_PN = 0.71, p_treat_ept = 0.79, p_treat_tr = 0.79, 
	independent = True, calibration = False, 
	analysis_window = 10, output_net = False): 

	'''
	Npop = 5000
	years = 5
	days = 14 # 14 days; bi-weekly time step
	run = np.random.choice(list(range(1, 1001)), 1)
	graph = "random"
	strategy = "PN" 
	pEFoI =  (1 / 5000) / 2
	independent = False
	calibration = True
	analysis_window = 2

	pContact_PN = 0.49
	pContact_ept = 0.7
	pContact_tr = 0.7
	p_treat_PN = 0.71
	p_treat_ept = 0.79
	p_treat_tr = 0.79

	# 4 strategies: do nothing, EPT, contact tracing_degree (contact high degree nodes first), contact tracing_chronology (first come, first serve.)
	'''

	degree = data.SexBehavior().degree
	degree_dist = data.SexBehavior().degree_dist
	mean_degree = np.sum(degree * degree_dist)
	Ndegree = mean_degree * years
	unit_per_year = int(365 / days)
	time_horizon = unit_per_year * years
	n_cluster = data.Params(unit_per_year).n_cluster
	pScr = data.Params(unit_per_year).pScr

	if calibration == False: 
		np.random.seed(run)

	ID = np.arange(Npop)
	ID_cluster = (np.floor(ID / (Npop/n_cluster)) + 1).astype(int)

	if graph == "random": 
		rel_hist = random_graph_generator(ID, Npop, Ndegree, time_horizon, independent = independent)
	elif graph == "community": 
		rel_hist = community_graph_generator(ID, Npop, Ndegree, ID_cluster, time_horizon, \
			pCluster = 0.99, independent = independent)
	elif graph == 'power_law': 
		rel_hist = power_law_graph_generator(ID, Npop, time_horizon, n_yrs = years, independent = independent)
	else: 
		rel_hist = empirical_graph_generator(ID, Npop, time_horizon, n_yrs = years, independent = independent)
	
	out_avg_degree = get_avg_degree_per_step(rel_hist, Npop, time_horizon)
	t_begin = (time_horizon - unit_per_year * analysis_window)

	if output_net == True: 
		net_out = summarize_net_result(rel_hist, Npop, t_begin)
		net_out['avg_deg_step'] = np.mean(out_avg_degree[t_begin:])
		return net_out

	# only keep network in the analysis window and shift the time 
	rel_hist[:, 2] = rel_hist[:, 2] - t_begin
	rel_hist[:, 3] = rel_hist[:, 3] - t_begin
	# update time horizon
	time_horizon  = time_horizon - t_begin
	out_avg_degree = out_avg_degree[t_begin:]

	tmp_name, tmp_count = np.unique(rel_hist[np.where(rel_hist[:, 3] >= 0), :2], return_counts = True) 
	count_all = np.zeros(Npop)
	count_all[tmp_name] = tmp_count

	net_sum = {}
	net_sum['avg_degree_step'] = np.mean(out_avg_degree)
	net_sum['avg_degree_all'] = np.mean(count_all)

	seed_ix = gen_inf_id_from_external(count_all, Npop, pEFoI, ID_cluster, graph, \
		time_horizon, inf_independent = True)

	scr_schedule = make_screening_schedule(rel_hist, time_horizon, Npop, unit_per_year, pScr)

	null_sum_all, null_I = implement_strategy(ID, rel_hist, Npop, time_horizon, unit_per_year, seed_ix, \
		scr_schedule, count_all, out_avg_degree, strategy = 'null', \
		pContact_PN = pContact_PN, pContact_ept = pContact_ept, pContact_tr = pContact_tr, \
		p_treat_PN = p_treat_PN, p_treat_ept = p_treat_ept, p_treat_tr = p_treat_tr)
	pn_sum_all, pn_I = implement_strategy(ID, rel_hist, Npop, time_horizon, unit_per_year, seed_ix, \
		scr_schedule, count_all, out_avg_degree, strategy = 'PN', \
		pContact_PN = pContact_PN, pContact_ept = pContact_ept, pContact_tr = pContact_tr, \
		p_treat_PN = p_treat_PN, p_treat_ept = p_treat_ept, p_treat_tr = p_treat_tr)
	ept_sum_all, ept_I = implement_strategy(ID, rel_hist, Npop, time_horizon, unit_per_year, seed_ix, \
		scr_schedule, count_all, out_avg_degree, strategy = 'EPT', \
		pContact_PN = pContact_PN, pContact_ept = pContact_ept, pContact_tr = pContact_tr, \
		p_treat_PN = p_treat_PN, p_treat_ept = p_treat_ept, p_treat_tr = p_treat_tr)
	tr_sum_all, tr_I = implement_strategy(ID, rel_hist, Npop, time_horizon, unit_per_year, seed_ix, \
		scr_schedule, count_all, out_avg_degree, strategy = 'tracing', \
		pContact_PN = pContact_PN, pContact_ept = pContact_ept, pContact_tr = pContact_tr, \
		p_treat_PN = p_treat_PN, p_treat_ept = p_treat_ept, p_treat_tr = p_treat_tr)

	return {"run": run, "net": net_sum, "null": null_sum_all, "pn": pn_sum_all, \
		"ept": ept_sum_all, "tracing": tr_sum_all} 



'''
import timeit

aa = timeit.default_timer()
run = np.random.choice(np.arange(10000), 1)
kk = SIR_net_generator(run, 5000, years = 5, days = 14, 
	graph = "power_law", pEFoI = 50 * (1 / 5000) / 2 , 
	pContact_PN = 0.49, pContact_ept = 0.7, pContact_tr = 0.7, 
	p_treat_PN = 0.71, p_treat_ept = 0.79, p_treat_tr = 0.79, 
	independent = False, calibration = False, 
	analysis_window = 2, output_net = False)
print(timeit.default_timer() - aa)
'''

